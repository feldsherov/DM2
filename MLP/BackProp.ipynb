{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BackProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['f', 'tanh', 'identity']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from scipy import misc\n",
    "import re\n",
    "%pylab inline\n",
    "\n",
    "from nn.MLP import MLP as MLP1\n",
    "from nn.Distances import d_log_Bernoulli_likelihood, log_Bernoulli_likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../DataSets/big_alphabet_29x29/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def l2dist(y, pred):\n",
    "    return np.sum((pred - y)**2, axis=1).reshape(pred.shape[0], 1)\n",
    "\n",
    "def d_l2dist(y, pred):\n",
    "    return 2 * (pred - y)\n",
    "\n",
    "def log_bernoulli(y, pred):\n",
    "    iy = 1 - y\n",
    "    ipred = 1 - pred\n",
    "    return -np.sum(y*np.log(pred) + iy*np.log(ipred), axis=1)\n",
    "\n",
    "def d_log_bernoulli(y, pred):\n",
    "    iy = 1 - y\n",
    "    ipred = 1 - pred\n",
    "    return -y/pred + iy/ipred\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def softmax(z):\n",
    "    ex = np.exp(z)\n",
    "    return ex / np.sum(ex, axis=1).reshape(ex.shape[0], 1)\n",
    "\n",
    "def d_softmax(m):\n",
    "    y = softmax(m)\n",
    "    return y * (1 - y)\n",
    "\n",
    "def idx(m):\n",
    "    return m\n",
    "\n",
    "def d_idx(m):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_dimension=None,\n",
    "                 layers=None,\n",
    "                 f_activation=None,\n",
    "                 df_activation=None,\n",
    "                 n_steps=200,\n",
    "                 seed=179,\n",
    "                 loss=l2dist,\n",
    "                 d_loss=d_l2dist,\n",
    "                 regularization='L2',\n",
    "                 learning_rate=0.1,\n",
    "                 verbose=True):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        if input_dimension is None:\n",
    "            raise ValueError(\"Input dimension must not be None\")\n",
    "\n",
    "        if layers is None:\n",
    "            self.n_layers = 10\n",
    "            layers = [self.n_layers for _ in range(self.n_layers)]\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        if f_activation is None or df_activation is None:\n",
    "            f_activation = [sigmoid for _ in range(self.n_layers)]\n",
    "            df_activation = [d_sigmoid for _ in range(self.n_layers)]\n",
    "\n",
    "        if loss is not None and d_loss is not None:\n",
    "            self.loss = loss\n",
    "            self.d_loss = d_loss\n",
    "        \n",
    "        self.w = [None] * self.n_layers\n",
    "        for i in range(0, self.n_layers):\n",
    "            prev = (layers[i - 1] if i != 0 else input_dimension)\n",
    "            nxt = layers[i]\n",
    "            self.w[i] = np.random.normal(0, 0.1, (prev + 1, nxt))\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.layers = layers\n",
    "        self.f_activation = f_activation\n",
    "        self.df_activation = df_activation\n",
    "\n",
    "        self.n_steps = n_steps\n",
    "        self.regularization = regularization\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X, Y, val_x, val_y, add_bias=True):\n",
    "        if add_bias:\n",
    "            X = np.concatenate((X, np.ones(X.shape[0]).reshape(X.shape[0], 1)), axis=1)\n",
    "\n",
    "        err_tr = list()\n",
    "        err_val = list()\n",
    "        Xs = [None] * self.n_layers\n",
    "        fXs = [None] * self.n_layers\n",
    "\n",
    "        for t in range(self.n_steps):\n",
    "            tmp = X\n",
    "            for i in range(self.n_layers):\n",
    "                Xs[i] = np.dot(tmp, self.w[i])\n",
    "                tmp = self.f_activation[i](Xs[i])\n",
    "                fXs[i] = tmp\n",
    "                if i != self.n_layers - 1:\n",
    "                    tmp = np.concatenate((tmp, np.ones(tmp.shape[0]).reshape(tmp.shape[0], 1)), axis=1)\n",
    "\n",
    "            err_tr.append(self.loss(Y, fXs[-1]).mean())\n",
    "            err_val.append(self.loss(val_y, self.predict(val_x)).mean())\n",
    "\n",
    "            gradW = [None] * self.n_layers\n",
    "            dE_n = None\n",
    "            for i in reversed(range(self.n_layers)):\n",
    "                dE = None\n",
    "                if i == self.n_layers - 1:\n",
    "                    dE = self.d_loss(Y, fXs[i]) * self.df_activation[i](Xs[i])\n",
    "                    dE_n = dE\n",
    "                else:\n",
    "                    dE = np.dot(self.w[i + 1][:-1, :], dE_n.T).T * self.df_activation[i](Xs[i])\n",
    "                    dE_n = dE\n",
    "                \n",
    "                inp = None\n",
    "                if i == 0:\n",
    "                    inp = X\n",
    "                else:\n",
    "                    inp = np.concatenate((fXs[i - 1], np.ones(fXs[i - 1].shape[0]).reshape(fXs[i - 1].shape[0], 1)), axis=1)\n",
    "\n",
    "                gradW[i] = np.dot(inp.T, dE) / len(X)\n",
    "                self.gradW = gradW\n",
    "                \n",
    "            for i in range(self.n_layers):\n",
    "                #if self.regularization == 'L2':\n",
    "                #    gradW[i] += 2*self.w[i]\n",
    "                self.w[i] -= self.learning_rate * gradW[i]\n",
    "            \n",
    "            if self.verbose:\n",
    "                print \"Iteration {0}, cv error={1}, train error={2}\".format(t, err_val[-1], err_tr[-1])\n",
    "\n",
    "        return err_tr, err_val\n",
    "\n",
    "    def predict(self, X, add_bias=True):\n",
    "        if add_bias:\n",
    "            X = np.concatenate((X, np.ones(X.shape[0]).reshape(X.shape[0], 1)), axis=1)\n",
    "\n",
    "        tmp = np.copy(X)\n",
    "        #print tmp\n",
    "        for i in range(0, self.n_layers):\n",
    "            tmp = np.dot(tmp, self.w[i])\n",
    "            tmp = self.f_activation[i](tmp)\n",
    "            #print tmp\n",
    "            if i != self.n_layers - 1:\n",
    "                tmp = np.concatenate((tmp, np.ones(tmp.shape[0]).reshape(tmp.shape[0], 1)), axis=1)\n",
    "\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list()\n",
    "target = list()\n",
    "classes = list()\n",
    "\n",
    "train_data_1 = list()\n",
    "train_target_1 = list()\n",
    "train_class_1 = list()\n",
    "\n",
    "data_n = np.empty((0, 29*29))\n",
    "target_n = np.empty((0, 26))\n",
    "for pt in os.listdir(DATA_PATH):\n",
    "    im = misc.imread(os.path.join(DATA_PATH, pt), flatten=True).flatten() / 255.0\n",
    "                       \n",
    "    data.append(im)\n",
    "    \n",
    "    parts = re.split('[-\\.]', pt)\n",
    "    \n",
    "    c_class = int(pt[:-4].split(\"-\")[1])\n",
    "    c_target = np.zeros(26)\n",
    "    c_target[c_class] = 1.0\n",
    "    target.append(c_target)\n",
    "    classes.append(c_class)\n",
    "    \n",
    "    if \"mutant\" not in parts or parts[2] not in [\"5\", \"6\", \"7\", \"8\"]:\n",
    "        train_data_1.append(im)\n",
    "        train_target_1.append(c_target)\n",
    "        train_class_1.append(c_class)\n",
    "    \n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "classes = np.array(classes)\n",
    "\n",
    "train_data_1 = np.array(train_data_1)\n",
    "train_target_1 = np.array(train_target_1)\n",
    "train_class_1 = np.array(train_class_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_idx = np.random.randint(0, 5, size=data.shape[0])\n",
    "\n",
    "train_data = data[train_idx != 0, ::] \n",
    "train_target = target[train_idx != 0, ::]\n",
    "train_classes = classes[train_idx != 0]\n",
    "\n",
    "val_data = data[train_idx == 0, ::] \n",
    "val_target = target[train_idx == 0, ::]\n",
    "val_classes = classes[train_idx == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 841)\n",
      "(53, 26)\n"
     ]
    }
   ],
   "source": [
    "print val_data.shape\n",
    "print val_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLP(input_dimension=29*29, \n",
    "          layers=[100 for i in range(1)] + [26], \n",
    "          f_activation=[sigmoid, softmax], \n",
    "          df_activation=[d_sigmoid, d_softmax],\n",
    "          n_steps=2000,\n",
    "          loss=log_bernoulli,\n",
    "          d_loss=d_log_bernoulli,\n",
    "          learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, cv error=4.3741928653, train error=4.57871442361\n",
      "Iteration 1, cv error=4.29778510731, train error=4.4384385648\n",
      "Iteration 2, cv error=4.26763159258, train error=4.365677777\n",
      "Iteration 3, cv error=4.25182949873, train error=4.31835440564\n",
      "Iteration 4, cv error=4.24163850098, train error=4.28321104044\n",
      "Iteration 5, cv error=4.23399052799, train error=4.25486269493\n",
      "Iteration 6, cv error=4.22764257417, train error=4.23083698775\n",
      "Iteration 7, cv error=4.22201519185, train error=4.20985594858\n",
      "Iteration 8, cv error=4.21679372653, train error=4.19117603004\n",
      "Iteration 9, cv error=4.21177960097, train error=4.17431196646\n",
      "Iteration 10, cv error=4.20683330638, train error=4.15891383536\n",
      "Iteration 11, cv error=4.20185348503, train error=4.14471083353\n",
      "Iteration 12, cv error=4.19676988518, train error=4.1314860669\n",
      "Iteration 13, cv error=4.19154030546, train error=4.11906623907\n",
      "Iteration 14, cv error=4.18614676364, train error=4.10731776651\n",
      "Iteration 15, cv error=4.1805886222, train error=4.09614327676\n",
      "Iteration 16, cv error=4.17487269687, train error=4.08547364795\n",
      "Iteration 17, cv error=4.16900367011, train error=4.07525443674\n",
      "Iteration 18, cv error=4.16298024404, train error=4.06543187469\n",
      "Iteration 19, cv error=4.15679907548, train error=4.05594618853\n",
      "Iteration 20, cv error=4.15046164174, train error=4.04673422753\n",
      "Iteration 21, cv error=4.1439774281, train error=4.03773607079\n",
      "Iteration 22, cv error=4.13736181788, train error=4.02889978446\n",
      "Iteration 23, cv error=4.13063157981, train error=4.02018267182\n",
      "Iteration 24, cv error=4.12380106217, train error=4.01155027695\n",
      "Iteration 25, cv error=4.11688034356, train error=4.00297471508\n",
      "Iteration 26, cv error=4.10987515171, train error=3.99443318136\n",
      "Iteration 27, cv error=4.10278785441, train error=3.98590687584\n",
      "Iteration 28, cv error=4.09561885785, train error=3.97738029402\n",
      "Iteration 29, cv error=4.088367946, train error=3.96884074984\n",
      "Iteration 30, cv error=4.08103528892, train error=3.96027800142\n",
      "Iteration 31, cv error=4.07362199672, train error=3.95168388239\n",
      "Iteration 32, cv error=4.06613020642, train error=3.94305188428\n",
      "Iteration 33, cv error=4.05856277785, train error=3.93437668328\n",
      "Iteration 34, cv error=4.05092274561, train error=3.9256536492\n",
      "Iteration 35, cv error=4.04321271347, train error=3.9168784028\n",
      "Iteration 36, cv error=4.03543437112, train error=3.90804648843\n",
      "Iteration 37, cv error=4.0275882565, train error=3.89915320144\n",
      "Iteration 38, cv error=4.01967379931, train error=3.89019356672\n",
      "Iteration 39, cv error=4.0116895938, train error=3.88116242417\n",
      "Iteration 40, cv error=4.00363379231, train error=3.87205455659\n",
      "Iteration 41, cv error=3.99550449784, train error=3.86286479726\n",
      "Iteration 42, cv error=3.98730005926, train error=3.853588076\n",
      "Iteration 43, cv error=3.97901922158, train error=3.84421939314\n",
      "Iteration 44, cv error=3.97066113548, train error=3.83475374141\n",
      "Iteration 45, cv error=3.96222527274, train error=3.82518602204\n",
      "Iteration 46, cv error=3.95371131645, train error=3.81551102002\n",
      "Iteration 47, cv error=3.94511909712, train error=3.80572351497\n",
      "Iteration 48, cv error=3.93644862998, train error=3.795818611\n",
      "Iteration 49, cv error=3.92770027929, train error=3.78579236607\n",
      "Iteration 50, cv error=3.91887503393, train error=3.77564277459\n",
      "Iteration 51, cv error=3.90997482185, train error=3.76537107266\n",
      "Iteration 52, cv error=3.90100272519, train error=3.75498315303\n",
      "Iteration 53, cv error=3.89196291399, train error=3.74449059993\n",
      "Iteration 54, cv error=3.88286017077, train error=3.73391061805\n",
      "Iteration 55, cv error=3.87369909686, train error=3.72326424218\n",
      "Iteration 56, cv error=3.86448339763, train error=3.71257292864\n",
      "Iteration 57, cv error=3.85521573876, train error=3.70185467559\n",
      "Iteration 58, cv error=3.84589830829, train error=3.69112131196\n",
      "Iteration 59, cv error=3.83653365702, train error=3.6803779209\n",
      "Iteration 60, cv error=3.82712520271, train error=3.66962408573\n",
      "Iteration 61, cv error=3.81767713192, train error=3.65885589113\n",
      "Iteration 62, cv error=3.80819388298, train error=3.64806775589\n",
      "Iteration 63, cv error=3.79867955054, train error=3.63725371308\n",
      "Iteration 64, cv error=3.78913744274, train error=3.62640815366\n",
      "Iteration 65, cv error=3.77956985906, train error=3.61552618914\n",
      "Iteration 66, cv error=3.76997805881, train error=3.60460377708\n",
      "Iteration 67, cv error=3.76036236011, train error=3.59363770449\n",
      "Iteration 68, cv error=3.75072231269, train error=3.5826254853\n",
      "Iteration 69, cv error=3.7410569014, train error=3.57156520672\n",
      "Iteration 70, cv error=3.73136474934, train error=3.56045535103\n",
      "Iteration 71, cv error=3.72164429901, train error=3.54929461704\n",
      "Iteration 72, cv error=3.71189395683, train error=3.53808176431\n",
      "Iteration 73, cv error=3.70211219254, train error=3.52681550036\n",
      "Iteration 74, cv error=3.69229759137, train error=3.51549442519\n",
      "Iteration 75, cv error=3.68244886298, train error=3.50411704086\n",
      "Iteration 76, cv error=3.67256481628, train error=3.49268182662\n",
      "Iteration 77, cv error=3.66264431185, train error=3.48118737471\n",
      "Iteration 78, cv error=3.6526862044, train error=3.46963257617\n",
      "Iteration 79, cv error=3.64268928648, train error=3.45801683971\n",
      "Iteration 80, cv error=3.63265224306, train error=3.44634031684\n",
      "Iteration 81, cv error=3.62257362588, train error=3.43460409506\n",
      "Iteration 82, cv error=3.61245185557, train error=3.42281031126\n",
      "Iteration 83, cv error=3.6022852581, train error=3.41096213795\n",
      "Iteration 84, cv error=3.59207213731, train error=3.39906361281\n",
      "Iteration 85, cv error=3.58181087611, train error=3.38711932035\n",
      "Iteration 86, cv error=3.57150004735, train error=3.37513398001\n",
      "Iteration 87, cv error=3.56113850708, train error=3.3631120283\n",
      "Iteration 88, cv error=3.55072544349, train error=3.35105728256\n",
      "Iteration 89, cv error=3.54026036668, train error=3.33897273942\n",
      "Iteration 90, cv error=3.52974304195, train error=3.32686051188\n",
      "Iteration 91, cv error=3.51917338411, train error=3.3147218705\n",
      "Iteration 92, cv error=3.50855133681, train error=3.302557341\n",
      "Iteration 93, cv error=3.49787675811, train error=3.29036682007\n",
      "Iteration 94, cv error=3.48714932723, train error=3.27814968904\n",
      "Iteration 95, cv error=3.47636848049, train error=3.26590492036\n",
      "Iteration 96, cv error=3.46553338125, train error=3.25363117968\n",
      "Iteration 97, cv error=3.4546429275, train error=3.24132692847\n",
      "Iteration 98, cv error=3.44369580337, train error=3.22899053232\n",
      "Iteration 99, cv error=3.43269058429, train error=3.21662038105\n",
      "Iteration 100, cv error=3.42162590994, train error=3.20421502871\n",
      "Iteration 101, cv error=3.41050074263, train error=3.19177336392\n",
      "Iteration 102, cv error=3.39931472707, train error=3.17929482025\n",
      "Iteration 103, cv error=3.38806865577, train error=3.16677962869\n",
      "Iteration 104, cv error=3.37676501459, train error=3.15422909613\n",
      "Iteration 105, cv error=3.36540853123, train error=3.14164586378\n",
      "Iteration 106, cv error=3.35400658062, train error=3.12903406363\n",
      "Iteration 107, cv error=3.34256924379, train error=3.11639926821\n",
      "Iteration 108, cv error=3.33110882038, train error=3.10374814804\n",
      "Iteration 109, cv error=3.3196387139, train error=3.091087833\n",
      "Iteration 110, cv error=3.30817184076, train error=3.07842510079\n",
      "Iteration 111, cv error=3.29671896266, train error=3.06576561952\n",
      "Iteration 112, cv error=3.28528744196, train error=3.05311347265\n",
      "Iteration 113, cv error=3.27388077484, train error=3.04047107635\n",
      "Iteration 114, cv error=3.26249893866, train error=3.02783943671\n",
      "Iteration 115, cv error=3.25113929736, train error=3.01521858744\n",
      "Iteration 116, cv error=3.23979769449, train error=3.00260804179\n",
      "Iteration 117, cv error=3.22846943272, train error=2.99000715374\n",
      "Iteration 118, cv error=3.21714999107, train error=2.97741535599\n",
      "Iteration 119, cv error=3.20583546429, train error=2.9648322897\n",
      "Iteration 120, cv error=3.19452278168, train error=2.95225785868\n",
      "Iteration 121, cv error=3.18320977927, train error=2.93969223936\n",
      "Iteration 122, cv error=3.17189518665, train error=2.92713586799\n",
      "Iteration 123, cv error=3.16057856793, train error=2.91458941751\n",
      "Iteration 124, cv error=3.14926023681, train error=2.9020537693\n",
      "Iteration 125, cv error=3.13794115378, train error=2.88952998113\n",
      "Iteration 126, cv error=3.1266228074, train error=2.87701925131\n",
      "Iteration 127, cv error=3.11530708116, train error=2.86452287916\n",
      "Iteration 128, cv error=3.10399610971, train error=2.85204222307\n",
      "Iteration 129, cv error=3.09269213172, train error=2.83957865835\n",
      "Iteration 130, cv error=3.08139734937, train error=2.82713353817\n",
      "Iteration 131, cv error=3.07011380511, train error=2.81470816046\n",
      "Iteration 132, cv error=3.05884328518, train error=2.80230374331\n",
      "Iteration 133, cv error=3.04758725564, train error=2.78992141\n",
      "Iteration 134, cv error=3.03634683252, train error=2.7775621833\n",
      "Iteration 135, cv error=3.0251227831, train error=2.7652269878\n",
      "Iteration 136, cv error=3.01391555242, train error=2.75291665807\n",
      "Iteration 137, cv error=3.00272530718, train error=2.74063195038\n",
      "Iteration 138, cv error=2.9915519893, train error=2.72837355589\n",
      "Iteration 139, cv error=2.98039537215, train error=2.71614211357\n",
      "Iteration 140, cv error=2.96925511431, train error=2.70393822189\n",
      "Iteration 141, cv error=2.95813080741, train error=2.69176244865\n",
      "Iteration 142, cv error=2.94702201637, train error=2.67961533873\n",
      "Iteration 143, cv error=2.93592831132, train error=2.66749741996\n",
      "Iteration 144, cv error=2.92484929172, train error=2.65540920729\n",
      "Iteration 145, cv error=2.91378460348, train error=2.64335120557\n",
      "Iteration 146, cv error=2.90273395013, train error=2.63132391132\n",
      "Iteration 147, cv error=2.89169709928, train error=2.61932781372\n",
      "Iteration 148, cv error=2.88067388529, train error=2.60736339506\n",
      "Iteration 149, cv error=2.86966420929, train error=2.59543113092\n",
      "Iteration 150, cv error=2.85866803707, train error=2.58353149001\n",
      "Iteration 151, cv error=2.84768539577, train error=2.57166493406\n",
      "Iteration 152, cv error=2.83671636959, train error=2.55983191753\n",
      "Iteration 153, cv error=2.82576109512, train error=2.54803288743\n",
      "Iteration 154, cv error=2.81481975639, train error=2.53626828311\n",
      "Iteration 155, cv error=2.80389257999, train error=2.5245385361\n",
      "Iteration 156, cv error=2.79297983029, train error=2.51284407003\n",
      "Iteration 157, cv error=2.78208180501, train error=2.50118530056\n",
      "Iteration 158, cv error=2.77119883094, train error=2.48956263536\n",
      "Iteration 159, cv error=2.76033126017, train error=2.47797647417\n",
      "Iteration 160, cv error=2.74947946658, train error=2.46642720886\n",
      "Iteration 161, cv error=2.73864384273, train error=2.4549152235\n",
      "Iteration 162, cv error=2.72782479705, train error=2.44344089448\n",
      "Iteration 163, cv error=2.71702275145, train error=2.43200459065\n",
      "Iteration 164, cv error=2.70623813915, train error=2.42060667343\n",
      "Iteration 165, cv error=2.69547140284, train error=2.40924749696\n",
      "Iteration 166, cv error=2.68472299306, train error=2.39792740819\n",
      "Iteration 167, cv error=2.67399336683, train error=2.38664674699\n",
      "Iteration 168, cv error=2.66328298643, train error=2.37540584625\n",
      "Iteration 169, cv error=2.65259231842, train error=2.36420503194\n",
      "Iteration 170, cv error=2.64192183267, train error=2.3530446231\n",
      "Iteration 171, cv error=2.63127200157, train error=2.34192493188\n",
      "Iteration 172, cv error=2.62064329937, train error=2.33084626348\n",
      "Iteration 173, cv error=2.6100362014, train error=2.31980891607\n",
      "Iteration 174, cv error=2.59945118353, train error=2.30881318068\n",
      "Iteration 175, cv error=2.58888872148, train error=2.29785934104\n",
      "Iteration 176, cv error=2.57834929023, train error=2.28694767341\n",
      "Iteration 177, cv error=2.56783336336, train error=2.27607844636\n",
      "Iteration 178, cv error=2.55734141243, train error=2.26525192053\n",
      "Iteration 179, cv error=2.54687390628, train error=2.25446834835\n",
      "Iteration 180, cv error=2.53643131035, train error=2.24372797381\n",
      "Iteration 181, cv error=2.52601408597, train error=2.23303103216\n",
      "Iteration 182, cv error=2.51562268963, train error=2.22237774962\n",
      "Iteration 183, cv error=2.50525757223, train error=2.21176834318\n",
      "Iteration 184, cv error=2.49491917843, train error=2.20120302029\n",
      "Iteration 185, cv error=2.48460794585, train error=2.19068197867\n",
      "Iteration 186, cv error=2.47432430448, train error=2.18020540616\n",
      "Iteration 187, cv error=2.46406867602, train error=2.16977348054\n",
      "Iteration 188, cv error=2.45384147328, train error=2.15938636943\n",
      "Iteration 189, cv error=2.44364309973, train error=2.14904423025\n",
      "Iteration 190, cv error=2.43347394898, train error=2.13874721024\n",
      "Iteration 191, cv error=2.4233344045, train error=2.12849544645\n",
      "Iteration 192, cv error=2.41322483928, train error=2.11828906585\n",
      "Iteration 193, cv error=2.40314561568, train error=2.10812818546\n",
      "Iteration 194, cv error=2.39309708526, train error=2.09801291254\n",
      "Iteration 195, cv error=2.3830795888, train error=2.08794334476\n",
      "Iteration 196, cv error=2.37309345631, train error=2.07791957045\n",
      "Iteration 197, cv error=2.36313900711, train error=2.06794166884\n",
      "Iteration 198, cv error=2.35321655002, train error=2.05800971037\n",
      "Iteration 199, cv error=2.34332638356, train error=2.04812375695\n",
      "Iteration 200, cv error=2.33346879615, train error=2.03828386225\n",
      "Iteration 201, cv error=2.32364406643, train error=2.02849007198\n",
      "Iteration 202, cv error=2.31385246349, train error=2.01874242422\n",
      "Iteration 203, cv error=2.3040942472, train error=2.00904094965\n",
      "Iteration 204, cv error=2.29436966847, train error=1.99938567185\n",
      "Iteration 205, cv error=2.2846789695, train error=1.98977660755\n",
      "Iteration 206, cv error=2.27502238413, train error=1.98021376685\n",
      "Iteration 207, cv error=2.26540013798, train error=1.97069715344\n",
      "Iteration 208, cv error=2.25581244872, train error=1.96122676485\n",
      "Iteration 209, cv error=2.24625952627, train error=1.95180259258\n",
      "Iteration 210, cv error=2.23674157294, train error=1.94242462228\n",
      "Iteration 211, cv error=2.22725878356, train error=1.93309283394\n",
      "Iteration 212, cv error=2.21781134563, train error=1.92380720198\n",
      "Iteration 213, cv error=2.20839943936, train error=1.91456769543\n",
      "Iteration 214, cv error=2.19902323781, train error=1.90537427799\n",
      "Iteration 215, cv error=2.18968290684, train error=1.89622690817\n",
      "Iteration 216, cv error=2.18037860524, train error=1.88712553939\n",
      "Iteration 217, cv error=2.17111048468, train error=1.87807012006\n",
      "Iteration 218, cv error=2.16187868977, train error=1.86906059364\n",
      "Iteration 219, cv error=2.15268335806, train error=1.86009689879\n",
      "Iteration 220, cv error=2.14352462005, train error=1.8511789694\n",
      "Iteration 221, cv error=2.13440259918, train error=1.84230673467\n",
      "Iteration 222, cv error=2.12531741189, train error=1.83348011922\n",
      "Iteration 223, cv error=2.11626916761, train error=1.82469904315\n",
      "Iteration 224, cv error=2.10725796879, train error=1.81596342213\n",
      "Iteration 225, cv error=2.09828391097, train error=1.80727316745\n",
      "Iteration 226, cv error=2.0893470828, train error=1.79862818615\n",
      "Iteration 227, cv error=2.08044756615, train error=1.79002838109\n",
      "Iteration 228, cv error=2.07158543612, train error=1.78147365101\n",
      "Iteration 229, cv error=2.06276076117, train error=1.77296389064\n",
      "Iteration 230, cv error=2.0539736032, train error=1.76449899078\n",
      "Iteration 231, cv error=2.04522401768, train error=1.75607883838\n",
      "Iteration 232, cv error=2.03651205371, train error=1.74770331662\n",
      "Iteration 233, cv error=2.02783775418, train error=1.73937230503\n",
      "Iteration 234, cv error=2.0192011559, train error=1.73108567953\n",
      "Iteration 235, cv error=2.01060228971, train error=1.72284331254\n",
      "Iteration 236, cv error=2.00204118059, train error=1.71464507306\n",
      "Iteration 237, cv error=1.99351784785, train error=1.70649082674\n",
      "Iteration 238, cv error=1.98503230522, train error=1.69838043595\n",
      "Iteration 239, cv error=1.97658456101, train error=1.69031375989\n",
      "Iteration 240, cv error=1.96817461823, train error=1.68229065463\n",
      "Iteration 241, cv error=1.9598024747, train error=1.67431097319\n",
      "Iteration 242, cv error=1.95146812321, train error=1.66637456562\n",
      "Iteration 243, cv error=1.94317155162, train error=1.65848127903\n",
      "Iteration 244, cv error=1.93491274297, train error=1.65063095772\n",
      "Iteration 245, cv error=1.92669167563, train error=1.64282344314\n",
      "Iteration 246, cv error=1.91850832333, train error=1.63505857405\n",
      "Iteration 247, cv error=1.91036265534, train error=1.62733618651\n",
      "Iteration 248, cv error=1.90225463651, train error=1.61965611394\n",
      "Iteration 249, cv error=1.89418422736, train error=1.61201818718\n",
      "Iteration 250, cv error=1.8861513842, train error=1.60442223454\n",
      "Iteration 251, cv error=1.87815605915, train error=1.59686808182\n",
      "Iteration 252, cv error=1.87019820025, train error=1.58935555236\n",
      "Iteration 253, cv error=1.86227775149, train error=1.58188446709\n",
      "Iteration 254, cv error=1.85439465289, train error=1.57445464456\n",
      "Iteration 255, cv error=1.84654884055, train error=1.56706590096\n",
      "Iteration 256, cv error=1.83874024668, train error=1.55971805017\n",
      "Iteration 257, cv error=1.83096879967, train error=1.55241090377\n",
      "Iteration 258, cv error=1.8232344241, train error=1.54514427109\n",
      "Iteration 259, cv error=1.81553704079, train error=1.53791795921\n",
      "Iteration 260, cv error=1.80787656684, train error=1.530731773\n",
      "Iteration 261, cv error=1.80025291563, train error=1.52358551518\n",
      "Iteration 262, cv error=1.79266599689, train error=1.51647898626\n",
      "Iteration 263, cv error=1.78511571668, train error=1.50941198464\n",
      "Iteration 264, cv error=1.77760197744, train error=1.50238430662\n",
      "Iteration 265, cv error=1.77012467801, train error=1.49539574638\n",
      "Iteration 266, cv error=1.76268371366, train error=1.48844609608\n",
      "Iteration 267, cv error=1.75527897607, train error=1.48153514584\n",
      "Iteration 268, cv error=1.74791035344, train error=1.47466268379\n",
      "Iteration 269, cv error=1.74057773042, train error=1.46782849609\n",
      "Iteration 270, cv error=1.7332809882, train error=1.46103236703\n",
      "Iteration 271, cv error=1.72602000456, train error=1.45427407902\n",
      "Iteration 272, cv error=1.71879465384, train error=1.44755341267\n",
      "Iteration 273, cv error=1.71160480707, train error=1.44087014688\n",
      "Iteration 274, cv error=1.70445033196, train error=1.4342240589\n",
      "Iteration 275, cv error=1.697331093, train error=1.42761492446\n",
      "Iteration 276, cv error=1.69024695153, train error=1.42104251783\n",
      "Iteration 277, cv error=1.68319776584, train error=1.41450661202\n",
      "Iteration 278, cv error=1.67618339126, train error=1.40800697887\n",
      "Iteration 279, cv error=1.66920368031, train error=1.40154338929\n",
      "Iteration 280, cv error=1.66225848283, train error=1.39511561346\n",
      "Iteration 281, cv error=1.65534764615, train error=1.38872342102\n",
      "Iteration 282, cv error=1.64847101531, train error=1.38236658144\n",
      "Iteration 283, cv error=1.64162843327, train error=1.37604486427\n",
      "Iteration 284, cv error=1.63481974118, train error=1.36975803951\n",
      "Iteration 285, cv error=1.62804477868, train error=1.36350587806\n",
      "Iteration 286, cv error=1.62130338421, train error=1.35728815212\n",
      "Iteration 287, cv error=1.61459539543, train error=1.35110463573\n",
      "Iteration 288, cv error=1.60792064961, train error=1.34495510531\n",
      "Iteration 289, cv error=1.60127898411, train error=1.33883934028\n",
      "Iteration 290, cv error=1.59467023685, train error=1.33275712369\n",
      "Iteration 291, cv error=1.5880942469, train error=1.32670824292\n",
      "Iteration 292, cv error=1.58155085502, train error=1.32069249042\n",
      "Iteration 293, cv error=1.57503990434, train error=1.31470966443\n",
      "Iteration 294, cv error=1.56856124091, train error=1.3087595698\n",
      "Iteration 295, cv error=1.56211471447, train error=1.30284201867\n",
      "Iteration 296, cv error=1.55570017901, train error=1.29695683127\n",
      "Iteration 297, cv error=1.5493174935, train error=1.29110383655\n",
      "Iteration 298, cv error=1.54296652246, train error=1.28528287282\n",
      "Iteration 299, cv error=1.53664713659, train error=1.27949378822\n",
      "Iteration 300, cv error=1.53035921326, train error=1.27373644112\n",
      "Iteration 301, cv error=1.52410263693, train error=1.2680107003\n",
      "Iteration 302, cv error=1.51787729953, train error=1.26231644496\n",
      "Iteration 303, cv error=1.51168310059, train error=1.25665356456\n",
      "Iteration 304, cv error=1.50551994739, train error=1.25102195839\n",
      "Iteration 305, cv error=1.49938775485, train error=1.24542153493\n",
      "Iteration 306, cv error=1.49328644535, train error=1.23985221099\n",
      "Iteration 307, cv error=1.48721594835, train error=1.23431391062\n",
      "Iteration 308, cv error=1.48117619991, train error=1.22880656386\n",
      "Iteration 309, cv error=1.47516714214, train error=1.22333010535\n",
      "Iteration 310, cv error=1.46918872247, train error=1.21788447281\n",
      "Iteration 311, cv error=1.46324089296, train error=1.21246960553\n",
      "Iteration 312, cv error=1.4573236095, train error=1.20708544284\n",
      "Iteration 313, cv error=1.45143683108, train error=1.20173192265\n",
      "Iteration 314, cv error=1.44558051904, train error=1.19640898017\n",
      "Iteration 315, cv error=1.43975463643, train error=1.19111654675\n",
      "Iteration 316, cv error=1.43395914736, train error=1.185854549\n",
      "Iteration 317, cv error=1.42819401656, train error=1.18062290806\n",
      "Iteration 318, cv error=1.42245920887, train error=1.17542153919\n",
      "Iteration 319, cv error=1.41675468898, train error=1.17025035158\n",
      "Iteration 320, cv error=1.41108042108, train error=1.16510924834\n",
      "Iteration 321, cv error=1.40543636865, train error=1.15999812679\n",
      "Iteration 322, cv error=1.39982249428, train error=1.15491687878\n",
      "Iteration 323, cv error=1.39423875945, train error=1.1498653912\n",
      "Iteration 324, cv error=1.38868512433, train error=1.14484354657\n",
      "Iteration 325, cv error=1.38316154755, train error=1.13985122364\n",
      "Iteration 326, cv error=1.37766798588, train error=1.13488829798\n",
      "Iteration 327, cv error=1.37220439395, train error=1.12995464255\n",
      "Iteration 328, cv error=1.36677072384, train error=1.12505012823\n",
      "Iteration 329, cv error=1.36136692461, train error=1.12017462421\n",
      "Iteration 330, cv error=1.35599294189, train error=1.11532799834\n",
      "Iteration 331, cv error=1.35064871733, train error=1.11051011738\n",
      "Iteration 332, cv error=1.34533418811, train error=1.10572084713\n",
      "Iteration 333, cv error=1.34004928642, train error=1.10096005249\n",
      "Iteration 334, cv error=1.33479393903, train error=1.09622759744\n",
      "Iteration 335, cv error=1.3295680668, train error=1.09152334499\n",
      "Iteration 336, cv error=1.32437158436, train error=1.08684715701\n",
      "Iteration 337, cv error=1.31920439982, train error=1.08219889409\n",
      "Iteration 338, cv error=1.31406641453, train error=1.07757841535\n",
      "Iteration 339, cv error=1.308957523, train error=1.07298557827\n",
      "Iteration 340, cv error=1.30387761289, train error=1.06842023849\n",
      "Iteration 341, cv error=1.29882656505, train error=1.0638822497\n",
      "Iteration 342, cv error=1.2938042537, train error=1.05937146344\n",
      "Iteration 343, cv error=1.28881054669, train error=1.05488772908\n",
      "Iteration 344, cv error=1.28384530581, train error=1.05043089371\n",
      "Iteration 345, cv error=1.27890838714, train error=1.04600080212\n",
      "Iteration 346, cv error=1.27399964152, train error=1.04159729686\n",
      "Iteration 347, cv error=1.26911891496, train error=1.03722021824\n",
      "Iteration 348, cv error=1.26426604916, train error=1.03286940448\n",
      "Iteration 349, cv error=1.25944088199, train error=1.02854469178\n",
      "Iteration 350, cv error=1.25464324795, train error=1.02424591449\n",
      "Iteration 351, cv error=1.24987297871, train error=1.01997290528\n",
      "Iteration 352, cv error=1.24512990353, train error=1.01572549534\n",
      "Iteration 353, cv error=1.24041384974, train error=1.01150351455\n",
      "Iteration 354, cv error=1.23572464312, train error=1.00730679173\n",
      "Iteration 355, cv error=1.23106210831, train error=1.00313515479\n",
      "Iteration 356, cv error=1.22642606917, train error=0.998988431013\n",
      "Iteration 357, cv error=1.2218163491, train error=0.994866447211\n",
      "Iteration 358, cv error=1.2172327713, train error=0.990769029948\n",
      "Iteration 359, cv error=1.21267515905, train error=0.986696005733\n",
      "Iteration 360, cv error=1.20814333595, train error=0.982647201195\n",
      "Iteration 361, cv error=1.20363712609, train error=0.978622443264\n",
      "Iteration 362, cv error=1.19915635422, train error=0.974621559319\n",
      "Iteration 363, cv error=1.19470084591, train error=0.970644377344\n",
      "Iteration 364, cv error=1.19027042766, train error=0.966690726049\n",
      "Iteration 365, cv error=1.18586492702, train error=0.962760434996\n",
      "Iteration 366, cv error=1.18148417265, train error=0.958853334701\n",
      "Iteration 367, cv error=1.1771279944, train error=0.954969256724\n",
      "Iteration 368, cv error=1.17279622337, train error=0.951108033752\n",
      "Iteration 369, cv error=1.16848869197, train error=0.947269499666\n",
      "Iteration 370, cv error=1.16420523391, train error=0.943453489596\n",
      "Iteration 371, cv error=1.15994568425, train error=0.939659839973\n",
      "Iteration 372, cv error=1.15570987943, train error=0.935888388564\n",
      "Iteration 373, cv error=1.15149765727, train error=0.932138974503\n",
      "Iteration 374, cv error=1.14730885696, train error=0.928411438313\n",
      "Iteration 375, cv error=1.14314331909, train error=0.924705621922\n",
      "Iteration 376, cv error=1.13900088562, train error=0.921021368674\n",
      "Iteration 377, cv error=1.13488139991, train error=0.917358523329\n",
      "Iteration 378, cv error=1.13078470666, train error=0.913716932071\n",
      "Iteration 379, cv error=1.12671065195, train error=0.910096442496\n",
      "Iteration 380, cv error=1.12265908322, train error=0.906496903609\n",
      "Iteration 381, cv error=1.11862984922, train error=0.902918165812\n",
      "Iteration 382, cv error=1.11462280004, train error=0.899360080893\n",
      "Iteration 383, cv error=1.11063778707, train error=0.89582250201\n",
      "Iteration 384, cv error=1.106674663, train error=0.892305283675\n",
      "Iteration 385, cv error=1.10273328179, train error=0.888808281735\n",
      "Iteration 386, cv error=1.09881349865, train error=0.885331353359\n",
      "Iteration 387, cv error=1.09491517006, train error=0.881874357009\n",
      "Iteration 388, cv error=1.09103815369, train error=0.878437152431\n",
      "Iteration 389, cv error=1.08718230844, train error=0.875019600626\n",
      "Iteration 390, cv error=1.08334749439, train error=0.871621563837\n",
      "Iteration 391, cv error=1.07953357281, train error=0.868242905523\n",
      "Iteration 392, cv error=1.07574040611, train error=0.864883490341\n",
      "Iteration 393, cv error=1.07196785785, train error=0.861543184128\n",
      "Iteration 394, cv error=1.0682157927, train error=0.858221853878\n",
      "Iteration 395, cv error=1.06448407645, train error=0.854919367725\n",
      "Iteration 396, cv error=1.06077257597, train error=0.851635594925\n",
      "Iteration 397, cv error=1.05708115921, train error=0.848370405834\n",
      "Iteration 398, cv error=1.05340969517, train error=0.845123671894\n",
      "Iteration 399, cv error=1.0497580539, train error=0.841895265612\n",
      "Iteration 400, cv error=1.04612610646, train error=0.838685060546\n",
      "Iteration 401, cv error=1.04251372494, train error=0.83549293129\n",
      "Iteration 402, cv error=1.03892078243, train error=0.832318753451\n",
      "Iteration 403, cv error=1.03534715297, train error=0.829162403642\n",
      "Iteration 404, cv error=1.0317927116, train error=0.826023759464\n",
      "Iteration 405, cv error=1.02825733429, train error=0.822902699489\n",
      "Iteration 406, cv error=1.02474089797, train error=0.819799103252\n",
      "Iteration 407, cv error=1.02124328048, train error=0.816712851232\n",
      "Iteration 408, cv error=1.01776436059, train error=0.813643824843\n",
      "Iteration 409, cv error=1.01430401794, train error=0.810591906419\n",
      "Iteration 410, cv error=1.01086213311, train error=0.807556979206\n",
      "Iteration 411, cv error=1.0074385875, train error=0.804538927347\n",
      "Iteration 412, cv error=1.00403326341, train error=0.801537635871\n",
      "Iteration 413, cv error=1.000646044, train error=0.798552990684\n",
      "Iteration 414, cv error=0.997276813233, train error=0.79558487856\n",
      "Iteration 415, cv error=0.993925455947, train error=0.792633187126\n",
      "Iteration 416, cv error=0.99059185778, train error=0.789697804858\n",
      "Iteration 417, cv error=0.987275905185, train error=0.786778621067\n",
      "Iteration 418, cv error=0.983977485418, train error=0.783875525896\n",
      "Iteration 419, cv error=0.980696486528, train error=0.780988410304\n",
      "Iteration 420, cv error=0.977432797346, train error=0.778117166063\n",
      "Iteration 421, cv error=0.974186307477, train error=0.775261685747\n",
      "Iteration 422, cv error=0.970956907292, train error=0.772421862727\n",
      "Iteration 423, cv error=0.96774448792, train error=0.76959759116\n",
      "Iteration 424, cv error=0.964548941237, train error=0.766788765983\n",
      "Iteration 425, cv error=0.961370159861, train error=0.763995282906\n",
      "Iteration 426, cv error=0.958208037143, train error=0.761217038406\n",
      "Iteration 427, cv error=0.95506246716, train error=0.758453929715\n",
      "Iteration 428, cv error=0.951933344707, train error=0.755705854822\n",
      "Iteration 429, cv error=0.94882056529, train error=0.752972712458\n",
      "Iteration 430, cv error=0.945724025121, train error=0.750254402095\n",
      "Iteration 431, cv error=0.942643621108, train error=0.747550823935\n",
      "Iteration 432, cv error=0.939579250851, train error=0.744861878912\n",
      "Iteration 433, cv error=0.936530812636, train error=0.742187468675\n",
      "Iteration 434, cv error=0.933498205426, train error=0.739527495592\n",
      "Iteration 435, cv error=0.930481328858, train error=0.736881862737\n",
      "Iteration 436, cv error=0.927480083237, train error=0.734250473891\n",
      "Iteration 437, cv error=0.924494369528, train error=0.73163323353\n",
      "Iteration 438, cv error=0.921524089353, train error=0.729030046823\n",
      "Iteration 439, cv error=0.918569144983, train error=0.726440819628\n",
      "Iteration 440, cv error=0.915629439336, train error=0.723865458482\n",
      "Iteration 441, cv error=0.91270487597, train error=0.721303870601\n",
      "Iteration 442, cv error=0.909795359078, train error=0.718755963871\n",
      "Iteration 443, cv error=0.906900793483, train error=0.716221646846\n",
      "Iteration 444, cv error=0.904021084635, train error=0.713700828741\n",
      "Iteration 445, cv error=0.901156138604, train error=0.711193419426\n",
      "Iteration 446, cv error=0.898305862077, train error=0.708699329425\n",
      "Iteration 447, cv error=0.895470162351, train error=0.706218469908\n",
      "Iteration 448, cv error=0.892648947334, train error=0.703750752688\n",
      "Iteration 449, cv error=0.889842125536, train error=0.701296090214\n",
      "Iteration 450, cv error=0.887049606066, train error=0.698854395569\n",
      "Iteration 451, cv error=0.884271298627, train error=0.696425582465\n",
      "Iteration 452, cv error=0.881507113517, train error=0.694009565237\n",
      "Iteration 453, cv error=0.878756961616, train error=0.69160625884\n",
      "Iteration 454, cv error=0.876020754392, train error=0.689215578844\n",
      "Iteration 455, cv error=0.873298403889, train error=0.686837441428\n",
      "Iteration 456, cv error=0.870589822729, train error=0.68447176338\n",
      "Iteration 457, cv error=0.867894924105, train error=0.682118462088\n",
      "Iteration 458, cv error=0.86521362178, train error=0.679777455538\n",
      "Iteration 459, cv error=0.862545830079, train error=0.67744866231\n",
      "Iteration 460, cv error=0.85989146389, train error=0.675132001572\n",
      "Iteration 461, cv error=0.85725043866, train error=0.672827393079\n",
      "Iteration 462, cv error=0.854622670389, train error=0.670534757165\n",
      "Iteration 463, cv error=0.852008075627, train error=0.668254014741\n",
      "Iteration 464, cv error=0.849406571474, train error=0.665985087293\n",
      "Iteration 465, cv error=0.846818075572, train error=0.663727896874\n",
      "Iteration 466, cv error=0.844242506107, train error=0.6614823661\n",
      "Iteration 467, cv error=0.841679781801, train error=0.659248418151\n",
      "Iteration 468, cv error=0.83912982191, train error=0.657025976763\n",
      "Iteration 469, cv error=0.836592546222, train error=0.654814966222\n",
      "Iteration 470, cv error=0.834067875055, train error=0.652615311367\n",
      "Iteration 471, cv error=0.831555729251, train error=0.65042693758\n",
      "Iteration 472, cv error=0.829056030174, train error=0.648249770783\n",
      "Iteration 473, cv error=0.826568699707, train error=0.646083737439\n",
      "Iteration 474, cv error=0.824093660249, train error=0.643928764542\n",
      "Iteration 475, cv error=0.821630834713, train error=0.641784779615\n",
      "Iteration 476, cv error=0.819180146523, train error=0.639651710711\n",
      "Iteration 477, cv error=0.816741519607, train error=0.637529486401\n",
      "Iteration 478, cv error=0.8143148784, train error=0.635418035777\n",
      "Iteration 479, cv error=0.811900147837, train error=0.633317288447\n",
      "Iteration 480, cv error=0.809497253352, train error=0.631227174528\n",
      "Iteration 481, cv error=0.807106120875, train error=0.629147624646\n",
      "Iteration 482, cv error=0.804726676827, train error=0.627078569932\n",
      "Iteration 483, cv error=0.802358848121, train error=0.625019942017\n",
      "Iteration 484, cv error=0.800002562155, train error=0.622971673027\n",
      "Iteration 485, cv error=0.797657746813, train error=0.620933695585\n",
      "Iteration 486, cv error=0.79532433046, train error=0.618905942802\n",
      "Iteration 487, cv error=0.793002241938, train error=0.616888348276\n",
      "Iteration 488, cv error=0.790691410567, train error=0.614880846087\n",
      "Iteration 489, cv error=0.788391766139, train error=0.612883370797\n",
      "Iteration 490, cv error=0.786103238917, train error=0.610895857441\n",
      "Iteration 491, cv error=0.783825759631, train error=0.60891824153\n",
      "Iteration 492, cv error=0.781559259477, train error=0.606950459042\n",
      "Iteration 493, cv error=0.779303670112, train error=0.604992446423\n",
      "Iteration 494, cv error=0.777058923653, train error=0.60304414058\n",
      "Iteration 495, cv error=0.774824952674, train error=0.601105478879\n",
      "Iteration 496, cv error=0.772601690204, train error=0.599176399144\n",
      "Iteration 497, cv error=0.770389069723, train error=0.597256839651\n",
      "Iteration 498, cv error=0.768187025158, train error=0.595346739125\n",
      "Iteration 499, cv error=0.765995490886, train error=0.593446036738\n",
      "Iteration 500, cv error=0.763814401725, train error=0.591554672105\n",
      "Iteration 501, cv error=0.761643692934, train error=0.58967258528\n",
      "Iteration 502, cv error=0.759483300212, train error=0.587799716754\n",
      "Iteration 503, cv error=0.757333159693, train error=0.585936007452\n",
      "Iteration 504, cv error=0.755193207944, train error=0.58408139873\n",
      "Iteration 505, cv error=0.753063381963, train error=0.58223583237\n",
      "Iteration 506, cv error=0.750943619177, train error=0.580399250579\n",
      "Iteration 507, cv error=0.748833857436, train error=0.578571595984\n",
      "Iteration 508, cv error=0.746734035016, train error=0.57675281163\n",
      "Iteration 509, cv error=0.744644090612, train error=0.57494284098\n",
      "Iteration 510, cv error=0.742563963336, train error=0.573141627905\n",
      "Iteration 511, cv error=0.740493592718, train error=0.571349116687\n",
      "Iteration 512, cv error=0.738432918698, train error=0.569565252014\n",
      "Iteration 513, cv error=0.736381881629, train error=0.567789978975\n",
      "Iteration 514, cv error=0.73434042227, train error=0.566023243063\n",
      "Iteration 515, cv error=0.732308481786, train error=0.564264990163\n",
      "Iteration 516, cv error=0.730286001746, train error=0.562515166559\n",
      "Iteration 517, cv error=0.728272924117, train error=0.560773718923\n",
      "Iteration 518, cv error=0.726269191267, train error=0.559040594317\n",
      "Iteration 519, cv error=0.724274745958, train error=0.557315740189\n",
      "Iteration 520, cv error=0.722289531344, train error=0.555599104366\n",
      "Iteration 521, cv error=0.720313490972, train error=0.553890635061\n",
      "Iteration 522, cv error=0.718346568776, train error=0.552190280859\n",
      "Iteration 523, cv error=0.716388709075, train error=0.550497990722\n",
      "Iteration 524, cv error=0.714439856574, train error=0.548813713982\n",
      "Iteration 525, cv error=0.712499956356, train error=0.54713740034\n",
      "Iteration 526, cv error=0.710568953884, train error=0.545468999866\n",
      "Iteration 527, cv error=0.708646794999, train error=0.543808462988\n",
      "Iteration 528, cv error=0.706733425913, train error=0.5421557405\n",
      "Iteration 529, cv error=0.70482879321, train error=0.54051078355\n",
      "Iteration 530, cv error=0.702932843844, train error=0.538873543643\n",
      "Iteration 531, cv error=0.701045525137, train error=0.537243972638\n",
      "Iteration 532, cv error=0.699166784773, train error=0.535622022741\n",
      "Iteration 533, cv error=0.6972965708, train error=0.534007646507\n",
      "Iteration 534, cv error=0.695434831623, train error=0.532400796838\n",
      "Iteration 535, cv error=0.693581516009, train error=0.530801426974\n",
      "Iteration 536, cv error=0.691736573076, train error=0.529209490498\n",
      "Iteration 537, cv error=0.689899952297, train error=0.527624941329\n",
      "Iteration 538, cv error=0.688071603495, train error=0.526047733721\n",
      "Iteration 539, cv error=0.686251476842, train error=0.524477822259\n",
      "Iteration 540, cv error=0.684439522856, train error=0.52291516186\n",
      "Iteration 541, cv error=0.682635692397, train error=0.521359707767\n",
      "Iteration 542, cv error=0.680839936668, train error=0.519811415546\n",
      "Iteration 543, cv error=0.679052207213, train error=0.518270241088\n",
      "Iteration 544, cv error=0.67727245591, train error=0.516736140603\n",
      "Iteration 545, cv error=0.675500634973, train error=0.515209070618\n",
      "Iteration 546, cv error=0.673736696949, train error=0.513688987976\n",
      "Iteration 547, cv error=0.671980594715, train error=0.512175849832\n",
      "Iteration 548, cv error=0.670232281477, train error=0.510669613651\n",
      "Iteration 549, cv error=0.668491710767, train error=0.509170237208\n",
      "Iteration 550, cv error=0.666758836439, train error=0.507677678581\n",
      "Iteration 551, cv error=0.665033612671, train error=0.506191896154\n",
      "Iteration 552, cv error=0.66331599396, train error=0.504712848611\n",
      "Iteration 553, cv error=0.661605935119, train error=0.503240494934\n",
      "Iteration 554, cv error=0.659903391278, train error=0.501774794403\n",
      "Iteration 555, cv error=0.658208317879, train error=0.500315706592\n",
      "Iteration 556, cv error=0.656520670677, train error=0.498863191367\n",
      "Iteration 557, cv error=0.654840405733, train error=0.497417208884\n",
      "Iteration 558, cv error=0.653167479416, train error=0.495977719587\n",
      "Iteration 559, cv error=0.651501848401, train error=0.494544684205\n",
      "Iteration 560, cv error=0.649843469664, train error=0.493118063751\n",
      "Iteration 561, cv error=0.648192300482, train error=0.49169781952\n",
      "Iteration 562, cv error=0.646548298432, train error=0.490283913084\n",
      "Iteration 563, cv error=0.644911421384, train error=0.488876306294\n",
      "Iteration 564, cv error=0.643281627505, train error=0.487474961275\n",
      "Iteration 565, cv error=0.641658875255, train error=0.486079840426\n",
      "Iteration 566, cv error=0.640043123383, train error=0.484690906415\n",
      "Iteration 567, cv error=0.638434330926, train error=0.48330812218\n",
      "Iteration 568, cv error=0.636832457208, train error=0.481931450926\n",
      "Iteration 569, cv error=0.635237461837, train error=0.480560856122\n",
      "Iteration 570, cv error=0.633649304704, train error=0.479196301499\n",
      "Iteration 571, cv error=0.63206794598, train error=0.47783775105\n",
      "Iteration 572, cv error=0.630493346115, train error=0.476485169028\n",
      "Iteration 573, cv error=0.628925465833, train error=0.475138519939\n",
      "Iteration 574, cv error=0.627364266137, train error=0.473797768547\n",
      "Iteration 575, cv error=0.625809708298, train error=0.472462879867\n",
      "Iteration 576, cv error=0.624261753861, train error=0.471133819167\n",
      "Iteration 577, cv error=0.622720364638, train error=0.469810551962\n",
      "Iteration 578, cv error=0.621185502708, train error=0.468493044017\n",
      "Iteration 579, cv error=0.619657130415, train error=0.467181261338\n",
      "Iteration 580, cv error=0.618135210367, train error=0.465875170178\n",
      "Iteration 581, cv error=0.616619705433, train error=0.464574737031\n",
      "Iteration 582, cv error=0.61511057874, train error=0.46327992863\n",
      "Iteration 583, cv error=0.613607793673, train error=0.461990711947\n",
      "Iteration 584, cv error=0.612111313874, train error=0.460707054189\n",
      "Iteration 585, cv error=0.610621103238, train error=0.459428922798\n",
      "Iteration 586, cv error=0.609137125911, train error=0.458156285449\n",
      "Iteration 587, cv error=0.60765934629, train error=0.456889110048\n",
      "Iteration 588, cv error=0.606187729021, train error=0.455627364728\n",
      "Iteration 589, cv error=0.604722238995, train error=0.454371017853\n",
      "Iteration 590, cv error=0.60326284135, train error=0.45312003801\n",
      "Iteration 591, cv error=0.601809501465, train error=0.45187439401\n",
      "Iteration 592, cv error=0.600362184962, train error=0.450634054888\n",
      "Iteration 593, cv error=0.5989208577, train error=0.449398989898\n",
      "Iteration 594, cv error=0.597485485778, train error=0.448169168515\n",
      "Iteration 595, cv error=0.596056035531, train error=0.446944560428\n",
      "Iteration 596, cv error=0.594632473528, train error=0.445725135544\n",
      "Iteration 597, cv error=0.593214766568, train error=0.444510863985\n",
      "Iteration 598, cv error=0.591802881686, train error=0.443301716083\n",
      "Iteration 599, cv error=0.590396786142, train error=0.442097662381\n",
      "Iteration 600, cv error=0.588996447426, train error=0.440898673633\n",
      "Iteration 601, cv error=0.587601833251, train error=0.439704720801\n",
      "Iteration 602, cv error=0.586212911558, train error=0.438515775049\n",
      "Iteration 603, cv error=0.584829650508, train error=0.437331807751\n",
      "Iteration 604, cv error=0.583452018484, train error=0.436152790481\n",
      "Iteration 605, cv error=0.582079984087, train error=0.434978695013\n",
      "Iteration 606, cv error=0.580713516137, train error=0.433809493325\n",
      "Iteration 607, cv error=0.579352583669, train error=0.432645157591\n",
      "Iteration 608, cv error=0.577997155935, train error=0.431485660182\n",
      "Iteration 609, cv error=0.576647202397, train error=0.430330973665\n",
      "Iteration 610, cv error=0.575302692728, train error=0.429181070801\n",
      "Iteration 611, cv error=0.573963596814, train error=0.428035924543\n",
      "Iteration 612, cv error=0.572629884747, train error=0.426895508037\n",
      "Iteration 613, cv error=0.571301526824, train error=0.425759794616\n",
      "Iteration 614, cv error=0.569978493552, train error=0.424628757804\n",
      "Iteration 615, cv error=0.568660755636, train error=0.42350237131\n",
      "Iteration 616, cv error=0.567348283987, train error=0.422380609028\n",
      "Iteration 617, cv error=0.566041049715, train error=0.421263445039\n",
      "Iteration 618, cv error=0.564739024129, train error=0.420150853605\n",
      "Iteration 619, cv error=0.563442178736, train error=0.419042809168\n",
      "Iteration 620, cv error=0.562150485239, train error=0.417939286351\n",
      "Iteration 621, cv error=0.560863915536, train error=0.416840259958\n",
      "Iteration 622, cv error=0.559582441717, train error=0.415745704967\n",
      "Iteration 623, cv error=0.558306036065, train error=0.414655596533\n",
      "Iteration 624, cv error=0.557034671053, train error=0.413569909986\n",
      "Iteration 625, cv error=0.555768319343, train error=0.412488620831\n",
      "Iteration 626, cv error=0.554506953783, train error=0.411411704741\n",
      "Iteration 627, cv error=0.553250547409, train error=0.410339137564\n",
      "Iteration 628, cv error=0.551999073441, train error=0.409270895315\n",
      "Iteration 629, cv error=0.550752505283, train error=0.408206954179\n",
      "Iteration 630, cv error=0.549510816519, train error=0.407147290505\n",
      "Iteration 631, cv error=0.548273980915, train error=0.406091880812\n",
      "Iteration 632, cv error=0.547041972417, train error=0.40504070178\n",
      "Iteration 633, cv error=0.545814765147, train error=0.403993730254\n",
      "Iteration 634, cv error=0.544592333404, train error=0.402950943241\n",
      "Iteration 635, cv error=0.543374651663, train error=0.401912317908\n",
      "Iteration 636, cv error=0.542161694572, train error=0.400877831581\n",
      "Iteration 637, cv error=0.540953436954, train error=0.399847461748\n",
      "Iteration 638, cv error=0.539749853799, train error=0.39882118605\n",
      "Iteration 639, cv error=0.538550920271, train error=0.397798982286\n",
      "Iteration 640, cv error=0.537356611701, train error=0.396780828411\n",
      "Iteration 641, cv error=0.536166903587, train error=0.395766702531\n",
      "Iteration 642, cv error=0.534981771595, train error=0.394756582908\n",
      "Iteration 643, cv error=0.533801191554, train error=0.393750447952\n",
      "Iteration 644, cv error=0.532625139458, train error=0.392748276226\n",
      "Iteration 645, cv error=0.531453591464, train error=0.39175004644\n",
      "Iteration 646, cv error=0.530286523888, train error=0.390755737454\n",
      "Iteration 647, cv error=0.52912391321, train error=0.389765328274\n",
      "Iteration 648, cv error=0.527965736066, train error=0.388778798051\n",
      "Iteration 649, cv error=0.52681196925, train error=0.387796126083\n",
      "Iteration 650, cv error=0.525662589713, train error=0.386817291809\n",
      "Iteration 651, cv error=0.524517574562, train error=0.385842274813\n",
      "Iteration 652, cv error=0.523376901057, train error=0.384871054818\n",
      "Iteration 653, cv error=0.522240546614, train error=0.383903611688\n",
      "Iteration 654, cv error=0.521108488797, train error=0.382939925429\n",
      "Iteration 655, cv error=0.519980705324, train error=0.381979976182\n",
      "Iteration 656, cv error=0.518857174061, train error=0.381023744226\n",
      "Iteration 657, cv error=0.517737873023, train error=0.380071209977\n",
      "Iteration 658, cv error=0.516622780373, train error=0.379122353985\n",
      "Iteration 659, cv error=0.515511874421, train error=0.378177156934\n",
      "Iteration 660, cv error=0.514405133621, train error=0.377235599644\n",
      "Iteration 661, cv error=0.513302536571, train error=0.376297663061\n",
      "Iteration 662, cv error=0.512204062016, train error=0.375363328269\n",
      "Iteration 663, cv error=0.511109688837, train error=0.374432576476\n",
      "Iteration 664, cv error=0.510019396063, train error=0.373505389022\n",
      "Iteration 665, cv error=0.508933162857, train error=0.372581747375\n",
      "Iteration 666, cv error=0.507850968525, train error=0.371661633129\n",
      "Iteration 667, cv error=0.506772792509, train error=0.370745028003\n",
      "Iteration 668, cv error=0.50569861439, train error=0.369831913844\n",
      "Iteration 669, cv error=0.504628413883, train error=0.36892227262\n",
      "Iteration 670, cv error=0.50356217084, train error=0.368016086423\n",
      "Iteration 671, cv error=0.502499865245, train error=0.367113337467\n",
      "Iteration 672, cv error=0.501441477216, train error=0.366214008088\n",
      "Iteration 673, cv error=0.500386987005, train error=0.36531808074\n",
      "Iteration 674, cv error=0.499336374991, train error=0.364425537997\n",
      "Iteration 675, cv error=0.498289621688, train error=0.363536362553\n",
      "Iteration 676, cv error=0.497246707734, train error=0.362650537216\n",
      "Iteration 677, cv error=0.4962076139, train error=0.361768044912\n",
      "Iteration 678, cv error=0.495172321082, train error=0.360888868682\n",
      "Iteration 679, cv error=0.494140810303, train error=0.360012991682\n",
      "Iteration 680, cv error=0.49311306271, train error=0.35914039718\n",
      "Iteration 681, cv error=0.492089059577, train error=0.358271068558\n",
      "Iteration 682, cv error=0.491068782301, train error=0.357404989307\n",
      "Iteration 683, cv error=0.490052212399, train error=0.356542143032\n",
      "Iteration 684, cv error=0.489039331513, train error=0.355682513446\n",
      "Iteration 685, cv error=0.488030121406, train error=0.354826084369\n",
      "Iteration 686, cv error=0.487024563958, train error=0.353972839731\n",
      "Iteration 687, cv error=0.486022641171, train error=0.35312276357\n",
      "Iteration 688, cv error=0.485024335165, train error=0.352275840027\n",
      "Iteration 689, cv error=0.484029628174, train error=0.351432053349\n",
      "Iteration 690, cv error=0.483038502554, train error=0.350591387889\n",
      "Iteration 691, cv error=0.482050940772, train error=0.349753828101\n",
      "Iteration 692, cv error=0.481066925412, train error=0.348919358542\n",
      "Iteration 693, cv error=0.480086439171, train error=0.348087963872\n",
      "Iteration 694, cv error=0.479109464859, train error=0.347259628848\n",
      "Iteration 695, cv error=0.478135985399, train error=0.346434338331\n",
      "Iteration 696, cv error=0.477165983825, train error=0.345612077277\n",
      "Iteration 697, cv error=0.47619944328, train error=0.344792830743\n",
      "Iteration 698, cv error=0.475236347018, train error=0.34397658388\n",
      "Iteration 699, cv error=0.474276678402, train error=0.343163321938\n",
      "Iteration 700, cv error=0.473320420901, train error=0.34235303026\n",
      "Iteration 701, cv error=0.472367558094, train error=0.341545694284\n",
      "Iteration 702, cv error=0.471418073664, train error=0.340741299542\n",
      "Iteration 703, cv error=0.470471951399, train error=0.339939831658\n",
      "Iteration 704, cv error=0.469529175194, train error=0.339141276347\n",
      "Iteration 705, cv error=0.468589729044, train error=0.338345619417\n",
      "Iteration 706, cv error=0.467653597051, train error=0.337552846764\n",
      "Iteration 707, cv error=0.466720763415, train error=0.336762944373\n",
      "Iteration 708, cv error=0.465791212441, train error=0.33597589832\n",
      "Iteration 709, cv error=0.464864928531, train error=0.335191694764\n",
      "Iteration 710, cv error=0.463941896189, train error=0.334410319953\n",
      "Iteration 711, cv error=0.463022100016, train error=0.333631760222\n",
      "Iteration 712, cv error=0.462105524711, train error=0.332856001988\n",
      "Iteration 713, cv error=0.461192155071, train error=0.332083031753\n",
      "Iteration 714, cv error=0.460281975989, train error=0.331312836102\n",
      "Iteration 715, cv error=0.459374972454, train error=0.330545401703\n",
      "Iteration 716, cv error=0.458471129546, train error=0.329780715305\n",
      "Iteration 717, cv error=0.457570432444, train error=0.329018763736\n",
      "Iteration 718, cv error=0.456672866416, train error=0.328259533906\n",
      "Iteration 719, cv error=0.455778416824, train error=0.327503012803\n",
      "Iteration 720, cv error=0.45488706912, train error=0.326749187492\n",
      "Iteration 721, cv error=0.453998808848, train error=0.325998045117\n",
      "Iteration 722, cv error=0.45311362164, train error=0.325249572897\n",
      "Iteration 723, cv error=0.452231493217, train error=0.324503758127\n",
      "Iteration 724, cv error=0.451352409391, train error=0.323760588177\n",
      "Iteration 725, cv error=0.450476356056, train error=0.32302005049\n",
      "Iteration 726, cv error=0.449603319197, train error=0.322282132583\n",
      "Iteration 727, cv error=0.448733284882, train error=0.321546822046\n",
      "Iteration 728, cv error=0.447866239266, train error=0.320814106539\n",
      "Iteration 729, cv error=0.447002168584, train error=0.320083973793\n",
      "Iteration 730, cv error=0.446141059159, train error=0.319356411609\n",
      "Iteration 731, cv error=0.445282897392, train error=0.318631407858\n",
      "Iteration 732, cv error=0.44442766977, train error=0.317908950479\n",
      "Iteration 733, cv error=0.443575362856, train error=0.317189027478\n",
      "Iteration 734, cv error=0.442725963298, train error=0.316471626928\n",
      "Iteration 735, cv error=0.441879457819, train error=0.315756736968\n",
      "Iteration 736, cv error=0.441035833223, train error=0.315044345803\n",
      "Iteration 737, cv error=0.44019507639, train error=0.314334441702\n",
      "Iteration 738, cv error=0.439357174278, train error=0.313627012998\n",
      "Iteration 739, cv error=0.438522113921, train error=0.312922048087\n",
      "Iteration 740, cv error=0.437689882428, train error=0.312219535428\n",
      "Iteration 741, cv error=0.436860466983, train error=0.31151946354\n",
      "Iteration 742, cv error=0.436033854844, train error=0.310821821004\n",
      "Iteration 743, cv error=0.435210033341, train error=0.310126596463\n",
      "Iteration 744, cv error=0.434388989878, train error=0.309433778616\n",
      "Iteration 745, cv error=0.433570711929, train error=0.308743356223\n",
      "Iteration 746, cv error=0.432755187041, train error=0.308055318103\n",
      "Iteration 747, cv error=0.431942402828, train error=0.307369653131\n",
      "Iteration 748, cv error=0.431132346978, train error=0.30668635024\n",
      "Iteration 749, cv error=0.430325007243, train error=0.306005398417\n",
      "Iteration 750, cv error=0.429520371447, train error=0.305326786708\n",
      "Iteration 751, cv error=0.428718427479, train error=0.304650504212\n",
      "Iteration 752, cv error=0.427919163296, train error=0.303976540083\n",
      "Iteration 753, cv error=0.42712256692, train error=0.303304883528\n",
      "Iteration 754, cv error=0.42632862644, train error=0.302635523808\n",
      "Iteration 755, cv error=0.425537330008, train error=0.301968450237\n",
      "Iteration 756, cv error=0.424748665843, train error=0.30130365218\n",
      "Iteration 757, cv error=0.423962622223, train error=0.300641119056\n",
      "Iteration 758, cv error=0.423179187493, train error=0.299980840331\n",
      "Iteration 759, cv error=0.422398350059, train error=0.299322805526\n",
      "Iteration 760, cv error=0.421620098388, train error=0.29866700421\n",
      "Iteration 761, cv error=0.420844421009, train error=0.298013426\n",
      "Iteration 762, cv error=0.420071306512, train error=0.297362060564\n",
      "Iteration 763, cv error=0.419300743545, train error=0.29671289762\n",
      "Iteration 764, cv error=0.418532720817, train error=0.296065926931\n",
      "Iteration 765, cv error=0.417767227097, train error=0.29542113831\n",
      "Iteration 766, cv error=0.417004251211, train error=0.294778521616\n",
      "Iteration 767, cv error=0.416243782042, train error=0.294138066758\n",
      "Iteration 768, cv error=0.415485808533, train error=0.293499763688\n",
      "Iteration 769, cv error=0.414730319683, train error=0.292863602406\n",
      "Iteration 770, cv error=0.413977304545, train error=0.292229572958\n",
      "Iteration 771, cv error=0.413226752233, train error=0.291597665436\n",
      "Iteration 772, cv error=0.412478651912, train error=0.290967869976\n",
      "Iteration 773, cv error=0.411732992806, train error=0.290340176762\n",
      "Iteration 774, cv error=0.41098976419, train error=0.28971457602\n",
      "Iteration 775, cv error=0.410248955397, train error=0.289091058023\n",
      "Iteration 776, cv error=0.409510555813, train error=0.288469613086\n",
      "Iteration 777, cv error=0.408774554876, train error=0.28785023157\n",
      "Iteration 778, cv error=0.408040942079, train error=0.28723290388\n",
      "Iteration 779, cv error=0.407309706969, train error=0.286617620466\n",
      "Iteration 780, cv error=0.406580839143, train error=0.28600437182\n",
      "Iteration 781, cv error=0.405854328254, train error=0.28539314848\n",
      "Iteration 782, cv error=0.405130164004, train error=0.284783941025\n",
      "Iteration 783, cv error=0.404408336148, train error=0.284176740081\n",
      "Iteration 784, cv error=0.403688834494, train error=0.283571536316\n",
      "Iteration 785, cv error=0.4029716489, train error=0.282968320443\n",
      "Iteration 786, cv error=0.402256769275, train error=0.282367083218\n",
      "Iteration 787, cv error=0.401544185581, train error=0.281767815441\n",
      "Iteration 788, cv error=0.400833887829, train error=0.281170507957\n",
      "Iteration 789, cv error=0.400125866082, train error=0.280575151654\n",
      "Iteration 790, cv error=0.399420110452, train error=0.279981737468\n",
      "Iteration 791, cv error=0.398716611103, train error=0.279390256374\n",
      "Iteration 792, cv error=0.398015358249, train error=0.278800699398\n",
      "Iteration 793, cv error=0.397316342154, train error=0.278213057608\n",
      "Iteration 794, cv error=0.396619553132, train error=0.277627322118\n",
      "Iteration 795, cv error=0.395924981547, train error=0.277043484087\n",
      "Iteration 796, cv error=0.395232617814, train error=0.276461534724\n",
      "Iteration 797, cv error=0.394542452396, train error=0.275881465282\n",
      "Iteration 798, cv error=0.393854475809, train error=0.275303267061\n",
      "Iteration 799, cv error=0.393168678615, train error=0.274726931411\n",
      "Iteration 800, cv error=0.39248505143, train error=0.274152449729\n",
      "Iteration 801, cv error=0.391803584918, train error=0.273579813461\n",
      "Iteration 802, cv error=0.391124269792, train error=0.273009014103\n",
      "Iteration 803, cv error=0.390447096816, train error=0.272440043201\n",
      "Iteration 804, cv error=0.389772056805, train error=0.271872892352\n",
      "Iteration 805, cv error=0.389099140624, train error=0.271307553206\n",
      "Iteration 806, cv error=0.388428339186, train error=0.270744017464\n",
      "Iteration 807, cv error=0.387759643456, train error=0.270182276881\n",
      "Iteration 808, cv error=0.38709304445, train error=0.269622323266\n",
      "Iteration 809, cv error=0.386428533233, train error=0.269064148484\n",
      "Iteration 810, cv error=0.385766100921, train error=0.268507744456\n",
      "Iteration 811, cv error=0.385105738682, train error=0.267953103159\n",
      "Iteration 812, cv error=0.384447437733, train error=0.267400216629\n",
      "Iteration 813, cv error=0.383791189343, train error=0.266849076962\n",
      "Iteration 814, cv error=0.383136984831, train error=0.266299676312\n",
      "Iteration 815, cv error=0.382484815569, train error=0.265752006898\n",
      "Iteration 816, cv error=0.381834672978, train error=0.265206060999\n",
      "Iteration 817, cv error=0.381186548533, train error=0.264661830959\n",
      "Iteration 818, cv error=0.380540433759, train error=0.264119309186\n",
      "Iteration 819, cv error=0.379896320232, train error=0.263578488156\n",
      "Iteration 820, cv error=0.379254199581, train error=0.26303936041\n",
      "Iteration 821, cv error=0.378614063488, train error=0.262501918562\n",
      "Iteration 822, cv error=0.377975903684, train error=0.261966155294\n",
      "Iteration 823, cv error=0.377339711955, train error=0.261432063358\n",
      "Iteration 824, cv error=0.376705480137, train error=0.260899635581\n",
      "Iteration 825, cv error=0.376073200121, train error=0.260368864866\n",
      "Iteration 826, cv error=0.375442863847, train error=0.259839744188\n",
      "Iteration 827, cv error=0.374814463309, train error=0.259312266601\n",
      "Iteration 828, cv error=0.374187990555, train error=0.258786425238\n",
      "Iteration 829, cv error=0.373563437682, train error=0.258262213311\n",
      "Iteration 830, cv error=0.372940796842, train error=0.257739624113\n",
      "Iteration 831, cv error=0.37232006024, train error=0.257218651019\n",
      "Iteration 832, cv error=0.371701220129, train error=0.25669928749\n",
      "Iteration 833, cv error=0.37108426882, train error=0.256181527068\n",
      "Iteration 834, cv error=0.370469198671, train error=0.255665363384\n",
      "Iteration 835, cv error=0.369856002095, train error=0.255150790157\n",
      "Iteration 836, cv error=0.369244671555, train error=0.25463780119\n",
      "Iteration 837, cv error=0.368635199568, train error=0.25412639038\n",
      "Iteration 838, cv error=0.368027578698, train error=0.253616551711\n",
      "Iteration 839, cv error=0.367421801565, train error=0.25310827926\n",
      "Iteration 840, cv error=0.366817860836, train error=0.252601567195\n",
      "Iteration 841, cv error=0.366215749229, train error=0.252096409775\n",
      "Iteration 842, cv error=0.365615459513, train error=0.251592801354\n",
      "Iteration 843, cv error=0.365016984505, train error=0.251090736379\n",
      "Iteration 844, cv error=0.364420317072, train error=0.25059020939\n",
      "Iteration 845, cv error=0.363825450129, train error=0.250091215021\n",
      "Iteration 846, cv error=0.363232376638, train error=0.249593747999\n",
      "Iteration 847, cv error=0.36264108961, train error=0.249097803147\n",
      "Iteration 848, cv error=0.362051582101, train error=0.248603375377\n",
      "Iteration 849, cv error=0.361463847213, train error=0.248110459699\n",
      "Iteration 850, cv error=0.360877878094, train error=0.247619051211\n",
      "Iteration 851, cv error=0.360293667935, train error=0.247129145104\n",
      "Iteration 852, cv error=0.359711209972, train error=0.24664073666\n",
      "Iteration 853, cv error=0.359130497481, train error=0.246153821247\n",
      "Iteration 854, cv error=0.358551523783, train error=0.245668394325\n",
      "Iteration 855, cv error=0.357974282238, train error=0.245184451436\n",
      "Iteration 856, cv error=0.357398766246, train error=0.244701988209\n",
      "Iteration 857, cv error=0.356824969246, train error=0.244221000354\n",
      "Iteration 858, cv error=0.356252884715, train error=0.243741483659\n",
      "Iteration 859, cv error=0.355682506167, train error=0.243263433994\n",
      "Iteration 860, cv error=0.355113827152, train error=0.2427868473\n",
      "Iteration 861, cv error=0.354546841253, train error=0.24231171959\n",
      "Iteration 862, cv error=0.353981542089, train error=0.241838046949\n",
      "Iteration 863, cv error=0.353417923312, train error=0.241365825526\n",
      "Iteration 864, cv error=0.352855978602, train error=0.240895051532\n",
      "Iteration 865, cv error=0.352295701675, train error=0.240425721237\n",
      "Iteration 866, cv error=0.351737086271, train error=0.239957830967\n",
      "Iteration 867, cv error=0.351180126163, train error=0.239491377097\n",
      "Iteration 868, cv error=0.350624815148, train error=0.239026356054\n",
      "Iteration 869, cv error=0.350071147053, train error=0.238562764302\n",
      "Iteration 870, cv error=0.349519115728, train error=0.238100598348\n",
      "Iteration 871, cv error=0.348968715049, train error=0.237639854733\n",
      "Iteration 872, cv error=0.348419938914, train error=0.237180530027\n",
      "Iteration 873, cv error=0.347872781248, train error=0.236722620825\n",
      "Iteration 874, cv error=0.347327235993, train error=0.236266123746\n",
      "Iteration 875, cv error=0.346783297117, train error=0.235811035421\n",
      "Iteration 876, cv error=0.346240958607, train error=0.235357352498\n",
      "Iteration 877, cv error=0.345700214469, train error=0.234905071629\n",
      "Iteration 878, cv error=0.345161058732, train error=0.234454189469\n",
      "Iteration 879, cv error=0.34462348544, train error=0.234004702672\n",
      "Iteration 880, cv error=0.344087488659, train error=0.233556607887\n",
      "Iteration 881, cv error=0.343553062472, train error=0.233109901751\n",
      "Iteration 882, cv error=0.343020200981, train error=0.232664580887\n",
      "Iteration 883, cv error=0.342488898305, train error=0.232220641899\n",
      "Iteration 884, cv error=0.341959148582, train error=0.23177808137\n",
      "Iteration 885, cv error=0.341430945965, train error=0.231336895853\n",
      "Iteration 886, cv error=0.340904284628, train error=0.230897081875\n",
      "Iteration 887, cv error=0.340379158761, train error=0.230458635927\n",
      "Iteration 888, cv error=0.339855562571, train error=0.230021554463\n",
      "Iteration 889, cv error=0.339333490284, train error=0.229585833899\n",
      "Iteration 890, cv error=0.338812936145, train error=0.229151470607\n",
      "Iteration 891, cv error=0.338293894414, train error=0.228718460915\n",
      "Iteration 892, cv error=0.337776359374, train error=0.228286801101\n",
      "Iteration 893, cv error=0.337260325325, train error=0.227856487398\n",
      "Iteration 894, cv error=0.336745786586, train error=0.227427515982\n",
      "Iteration 895, cv error=0.336232737496, train error=0.22699988298\n",
      "Iteration 896, cv error=0.335721172416, train error=0.226573584464\n",
      "Iteration 897, cv error=0.335211085726, train error=0.226148616448\n",
      "Iteration 898, cv error=0.334702471828, train error=0.225724974894\n",
      "Iteration 899, cv error=0.334195325147, train error=0.225302655702\n",
      "Iteration 900, cv error=0.333689640128, train error=0.22488165472\n",
      "Iteration 901, cv error=0.333185411243, train error=0.224461967735\n",
      "Iteration 902, cv error=0.332682632983, train error=0.224043590479\n",
      "Iteration 903, cv error=0.332181299866, train error=0.223626518625\n",
      "Iteration 904, cv error=0.331681406434, train error=0.223210747793\n",
      "Iteration 905, cv error=0.331182947254, train error=0.222796273544\n",
      "Iteration 906, cv error=0.33068591692, train error=0.222383091387\n",
      "Iteration 907, cv error=0.330190310049, train error=0.221971196778\n",
      "Iteration 908, cv error=0.329696121289, train error=0.221560585119\n",
      "Iteration 909, cv error=0.329203345311, train error=0.221151251763\n",
      "Iteration 910, cv error=0.328711976817, train error=0.220743192015\n",
      "Iteration 911, cv error=0.328222010535, train error=0.220336401131\n",
      "Iteration 912, cv error=0.327733441222, train error=0.219930874324\n",
      "Iteration 913, cv error=0.327246263663, train error=0.219526606763\n",
      "Iteration 914, cv error=0.326760472672, train error=0.219123593577\n",
      "Iteration 915, cv error=0.326276063094, train error=0.218721829854\n",
      "Iteration 916, cv error=0.325793029801, train error=0.218321310649\n",
      "Iteration 917, cv error=0.325311367695, train error=0.217922030981\n",
      "Iteration 918, cv error=0.324831071709, train error=0.217523985837\n",
      "Iteration 919, cv error=0.324352136804, train error=0.217127170177\n",
      "Iteration 920, cv error=0.323874557971, train error=0.216731578932\n",
      "Iteration 921, cv error=0.323398330233, train error=0.21633720701\n",
      "Iteration 922, cv error=0.32292344864, train error=0.215944049297\n",
      "Iteration 923, cv error=0.322449908273, train error=0.21555210066\n",
      "Iteration 924, cv error=0.321977704243, train error=0.215161355949\n",
      "Iteration 925, cv error=0.321506831688, train error=0.214771809998\n",
      "Iteration 926, cv error=0.321037285778, train error=0.214383457632\n",
      "Iteration 927, cv error=0.32056906171, train error=0.213996293664\n",
      "Iteration 928, cv error=0.320102154712, train error=0.213610312902\n",
      "Iteration 929, cv error=0.319636560039, train error=0.213225510146\n",
      "Iteration 930, cv error=0.319172272973, train error=0.212841880195\n",
      "Iteration 931, cv error=0.318709288827, train error=0.212459417847\n",
      "Iteration 932, cv error=0.318247602938, train error=0.212078117903\n",
      "Iteration 933, cv error=0.317787210674, train error=0.211697975164\n",
      "Iteration 934, cv error=0.317328107426, train error=0.211318984441\n",
      "Iteration 935, cv error=0.316870288613, train error=0.210941140547\n",
      "Iteration 936, cv error=0.316413749681, train error=0.210564438309\n",
      "Iteration 937, cv error=0.315958486101, train error=0.210188872563\n",
      "Iteration 938, cv error=0.315504493367, train error=0.209814438156\n",
      "Iteration 939, cv error=0.315051767001, train error=0.209441129951\n",
      "Iteration 940, cv error=0.314600302546, train error=0.209068942827\n",
      "Iteration 941, cv error=0.314150095572, train error=0.208697871678\n",
      "Iteration 942, cv error=0.313701141669, train error=0.208327911419\n",
      "Iteration 943, cv error=0.313253436453, train error=0.207959056981\n",
      "Iteration 944, cv error=0.31280697556, train error=0.207591303321\n",
      "Iteration 945, cv error=0.312361754649, train error=0.207224645412\n",
      "Iteration 946, cv error=0.3119177694, train error=0.206859078255\n",
      "Iteration 947, cv error=0.311475015514, train error=0.206494596873\n",
      "Iteration 948, cv error=0.311033488714, train error=0.206131196313\n",
      "Iteration 949, cv error=0.310593184741, train error=0.20576887165\n",
      "Iteration 950, cv error=0.310154099356, train error=0.205407617983\n",
      "Iteration 951, cv error=0.309716228342, train error=0.205047430439\n",
      "Iteration 952, cv error=0.309279567498, train error=0.204688304174\n",
      "Iteration 953, cv error=0.308844112642, train error=0.204330234372\n",
      "Iteration 954, cv error=0.308409859611, train error=0.203973216245\n",
      "Iteration 955, cv error=0.307976804259, train error=0.203617245035\n",
      "Iteration 956, cv error=0.307544942457, train error=0.203262316014\n",
      "Iteration 957, cv error=0.307114270095, train error=0.202908424484\n",
      "Iteration 958, cv error=0.306684783077, train error=0.202555565777\n",
      "Iteration 959, cv error=0.306256477326, train error=0.202203735257\n",
      "Iteration 960, cv error=0.305829348777, train error=0.201852928318\n",
      "Iteration 961, cv error=0.305403393386, train error=0.201503140385\n",
      "Iteration 962, cv error=0.30497860712, train error=0.201154366917\n",
      "Iteration 963, cv error=0.304554985964, train error=0.2008066034\n",
      "Iteration 964, cv error=0.304132525916, train error=0.200459845356\n",
      "Iteration 965, cv error=0.303711222989, train error=0.200114088335\n",
      "Iteration 966, cv error=0.303291073211, train error=0.199769327921\n",
      "Iteration 967, cv error=0.302872072625, train error=0.199425559728\n",
      "Iteration 968, cv error=0.302454217285, train error=0.199082779403\n",
      "Iteration 969, cv error=0.302037503261, train error=0.198740982624\n",
      "Iteration 970, cv error=0.301621926637, train error=0.198400165099\n",
      "Iteration 971, cv error=0.301207483508, train error=0.198060322571\n",
      "Iteration 972, cv error=0.300794169984, train error=0.197721450809\n",
      "Iteration 973, cv error=0.300381982189, train error=0.197383545617\n",
      "Iteration 974, cv error=0.299970916257, train error=0.197046602828\n",
      "Iteration 975, cv error=0.299560968336, train error=0.196710618307\n",
      "Iteration 976, cv error=0.299152134587, train error=0.196375587948\n",
      "Iteration 977, cv error=0.298744411185, train error=0.196041507676\n",
      "Iteration 978, cv error=0.298337794313, train error=0.195708373446\n",
      "Iteration 979, cv error=0.297932280171, train error=0.195376181243\n",
      "Iteration 980, cv error=0.297527864968, train error=0.195044927081\n",
      "Iteration 981, cv error=0.297124544927, train error=0.194714607003\n",
      "Iteration 982, cv error=0.296722316281, train error=0.194385217084\n",
      "Iteration 983, cv error=0.296321175277, train error=0.194056753423\n",
      "Iteration 984, cv error=0.295921118173, train error=0.193729212151\n",
      "Iteration 985, cv error=0.295522141239, train error=0.193402589427\n",
      "Iteration 986, cv error=0.295124240757, train error=0.193076881436\n",
      "Iteration 987, cv error=0.294727413019, train error=0.192752084392\n",
      "Iteration 988, cv error=0.29433165433, train error=0.192428194538\n",
      "Iteration 989, cv error=0.293936961008, train error=0.192105208141\n",
      "Iteration 990, cv error=0.293543329381, train error=0.191783121496\n",
      "Iteration 991, cv error=0.293150755788, train error=0.191461930925\n",
      "Iteration 992, cv error=0.29275923658, train error=0.191141632777\n",
      "Iteration 993, cv error=0.292368768121, train error=0.190822223425\n",
      "Iteration 994, cv error=0.291979346785, train error=0.190503699269\n",
      "Iteration 995, cv error=0.291590968957, train error=0.190186056735\n",
      "Iteration 996, cv error=0.291203631036, train error=0.189869292271\n",
      "Iteration 997, cv error=0.29081732943, train error=0.189553402353\n",
      "Iteration 998, cv error=0.290432060559, train error=0.189238383481\n",
      "Iteration 999, cv error=0.290047820855, train error=0.188924232177\n",
      "Iteration 1000, cv error=0.289664606761, train error=0.188610944989\n",
      "Iteration 1001, cv error=0.289282414732, train error=0.188298518489\n",
      "Iteration 1002, cv error=0.288901241235, train error=0.187986949271\n",
      "Iteration 1003, cv error=0.288521082746, train error=0.187676233952\n",
      "Iteration 1004, cv error=0.288141935755, train error=0.187366369172\n",
      "Iteration 1005, cv error=0.287763796763, train error=0.187057351595\n",
      "Iteration 1006, cv error=0.287386662281, train error=0.186749177906\n",
      "Iteration 1007, cv error=0.287010528833, train error=0.186441844811\n",
      "Iteration 1008, cv error=0.286635392954, train error=0.18613534904\n",
      "Iteration 1009, cv error=0.286261251191, train error=0.185829687343\n",
      "Iteration 1010, cv error=0.285888100101, train error=0.185524856491\n",
      "Iteration 1011, cv error=0.285515936254, train error=0.185220853276\n",
      "Iteration 1012, cv error=0.285144756231, train error=0.184917674513\n",
      "Iteration 1013, cv error=0.284774556625, train error=0.184615317034\n",
      "Iteration 1014, cv error=0.28440533404, train error=0.184313777693\n",
      "Iteration 1015, cv error=0.28403708509, train error=0.184013053364\n",
      "Iteration 1016, cv error=0.283669806405, train error=0.183713140941\n",
      "Iteration 1017, cv error=0.283303494621, train error=0.183414037336\n",
      "Iteration 1018, cv error=0.282938146389, train error=0.183115739482\n",
      "Iteration 1019, cv error=0.282573758372, train error=0.182818244331\n",
      "Iteration 1020, cv error=0.282210327241, train error=0.182521548851\n",
      "Iteration 1021, cv error=0.281847849683, train error=0.182225650033\n",
      "Iteration 1022, cv error=0.281486322393, train error=0.181930544883\n",
      "Iteration 1023, cv error=0.28112574208, train error=0.181636230426\n",
      "Iteration 1024, cv error=0.280766105462, train error=0.181342703706\n",
      "Iteration 1025, cv error=0.280407409272, train error=0.181049961784\n",
      "Iteration 1026, cv error=0.28004965025, train error=0.180758001738\n",
      "Iteration 1027, cv error=0.279692825153, train error=0.180466820664\n",
      "Iteration 1028, cv error=0.279336930744, train error=0.180176415676\n",
      "Iteration 1029, cv error=0.278981963802, train error=0.179886783903\n",
      "Iteration 1030, cv error=0.278627921115, train error=0.179597922492\n",
      "Iteration 1031, cv error=0.278274799483, train error=0.179309828608\n",
      "Iteration 1032, cv error=0.277922595718, train error=0.179022499429\n",
      "Iteration 1033, cv error=0.277571306643, train error=0.178735932151\n",
      "Iteration 1034, cv error=0.277220929093, train error=0.178450123988\n",
      "Iteration 1035, cv error=0.276871459913, train error=0.178165072166\n",
      "Iteration 1036, cv error=0.276522895962, train error=0.17788077393\n",
      "Iteration 1037, cv error=0.276175234109, train error=0.177597226539\n",
      "Iteration 1038, cv error=0.275828471233, train error=0.177314427267\n",
      "Iteration 1039, cv error=0.275482604227, train error=0.177032373405\n",
      "Iteration 1040, cv error=0.275137629994, train error=0.176751062257\n",
      "Iteration 1041, cv error=0.274793545449, train error=0.176470491143\n",
      "Iteration 1042, cv error=0.274450347517, train error=0.176190657397\n",
      "Iteration 1043, cv error=0.274108033137, train error=0.175911558369\n",
      "Iteration 1044, cv error=0.273766599256, train error=0.175633191423\n",
      "Iteration 1045, cv error=0.273426042834, train error=0.175355553936\n",
      "Iteration 1046, cv error=0.273086360843, train error=0.1750786433\n",
      "Iteration 1047, cv error=0.272747550264, train error=0.174802456921\n",
      "Iteration 1048, cv error=0.272409608093, train error=0.174526992219\n",
      "Iteration 1049, cv error=0.272072531333, train error=0.174252246627\n",
      "Iteration 1050, cv error=0.271736317, train error=0.173978217594\n",
      "Iteration 1051, cv error=0.271400962123, train error=0.173704902578\n",
      "Iteration 1052, cv error=0.271066463738, train error=0.173432299055\n",
      "Iteration 1053, cv error=0.270732818895, train error=0.173160404512\n",
      "Iteration 1054, cv error=0.270400024655, train error=0.172889216448\n",
      "Iteration 1055, cv error=0.270068078088, train error=0.172618732377\n",
      "Iteration 1056, cv error=0.269736976279, train error=0.172348949825\n",
      "Iteration 1057, cv error=0.269406716319, train error=0.17207986633\n",
      "Iteration 1058, cv error=0.269077295313, train error=0.171811479444\n",
      "Iteration 1059, cv error=0.268748710376, train error=0.171543786731\n",
      "Iteration 1060, cv error=0.268420958634, train error=0.171276785766\n",
      "Iteration 1061, cv error=0.268094037225, train error=0.171010474137\n",
      "Iteration 1062, cv error=0.267767943296, train error=0.170744849446\n",
      "Iteration 1063, cv error=0.267442674005, train error=0.170479909304\n",
      "Iteration 1064, cv error=0.267118226521, train error=0.170215651336\n",
      "Iteration 1065, cv error=0.266794598025, train error=0.169952073178\n",
      "Iteration 1066, cv error=0.266471785707, train error=0.169689172477\n",
      "Iteration 1067, cv error=0.266149786768, train error=0.169426946893\n",
      "Iteration 1068, cv error=0.265828598419, train error=0.169165394097\n",
      "Iteration 1069, cv error=0.265508217884, train error=0.168904511771\n",
      "Iteration 1070, cv error=0.265188642395, train error=0.168644297609\n",
      "Iteration 1071, cv error=0.264869869195, train error=0.168384749314\n",
      "Iteration 1072, cv error=0.264551895537, train error=0.168125864603\n",
      "Iteration 1073, cv error=0.264234718687, train error=0.167867641203\n",
      "Iteration 1074, cv error=0.263918335918, train error=0.167610076851\n",
      "Iteration 1075, cv error=0.263602744516, train error=0.167353169295\n",
      "Iteration 1076, cv error=0.263287941775, train error=0.167096916295\n",
      "Iteration 1077, cv error=0.262973925001, train error=0.16684131562\n",
      "Iteration 1078, cv error=0.262660691509, train error=0.16658636505\n",
      "Iteration 1079, cv error=0.262348238626, train error=0.166332062376\n",
      "Iteration 1080, cv error=0.262036563686, train error=0.1660784054\n",
      "Iteration 1081, cv error=0.261725664037, train error=0.165825391932\n",
      "Iteration 1082, cv error=0.261415537033, train error=0.165573019794\n",
      "Iteration 1083, cv error=0.261106180042, train error=0.165321286817\n",
      "Iteration 1084, cv error=0.260797590438, train error=0.165070190843\n",
      "Iteration 1085, cv error=0.260489765609, train error=0.164819729724\n",
      "Iteration 1086, cv error=0.26018270295, train error=0.164569901321\n",
      "Iteration 1087, cv error=0.259876399867, train error=0.164320703504\n",
      "Iteration 1088, cv error=0.259570853775, train error=0.164072134155\n",
      "Iteration 1089, cv error=0.2592660621, train error=0.163824191165\n",
      "Iteration 1090, cv error=0.258962022278, train error=0.163576872433\n",
      "Iteration 1091, cv error=0.258658731752, train error=0.163330175869\n",
      "Iteration 1092, cv error=0.258356187978, train error=0.163084099391\n",
      "Iteration 1093, cv error=0.258054388419, train error=0.162838640928\n",
      "Iteration 1094, cv error=0.257753330551, train error=0.162593798417\n",
      "Iteration 1095, cv error=0.257453011855, train error=0.162349569805\n",
      "Iteration 1096, cv error=0.257153429825, train error=0.162105953048\n",
      "Iteration 1097, cv error=0.256854581963, train error=0.16186294611\n",
      "Iteration 1098, cv error=0.256556465782, train error=0.161620546964\n",
      "Iteration 1099, cv error=0.256259078803, train error=0.161378753595\n",
      "Iteration 1100, cv error=0.255962418556, train error=0.161137563993\n",
      "Iteration 1101, cv error=0.255666482581, train error=0.160896976158\n",
      "Iteration 1102, cv error=0.255371268429, train error=0.1606569881\n",
      "Iteration 1103, cv error=0.255076773656, train error=0.160417597836\n",
      "Iteration 1104, cv error=0.254782995833, train error=0.160178803391\n",
      "Iteration 1105, cv error=0.254489932535, train error=0.159940602802\n",
      "Iteration 1106, cv error=0.254197581349, train error=0.159702994111\n",
      "Iteration 1107, cv error=0.253905939871, train error=0.159465975369\n",
      "Iteration 1108, cv error=0.253615005705, train error=0.159229544637\n",
      "Iteration 1109, cv error=0.253324776464, train error=0.158993699983\n",
      "Iteration 1110, cv error=0.253035249773, train error=0.158758439482\n",
      "Iteration 1111, cv error=0.252746423261, train error=0.158523761221\n",
      "Iteration 1112, cv error=0.252458294571, train error=0.15828966329\n",
      "Iteration 1113, cv error=0.252170861352, train error=0.158056143791\n",
      "Iteration 1114, cv error=0.251884121261, train error=0.157823200833\n",
      "Iteration 1115, cv error=0.251598071968, train error=0.157590832532\n",
      "Iteration 1116, cv error=0.251312711148, train error=0.157359037013\n",
      "Iteration 1117, cv error=0.251028036487, train error=0.157127812407\n",
      "Iteration 1118, cv error=0.250744045678, train error=0.156897156856\n",
      "Iteration 1119, cv error=0.250460736424, train error=0.156667068506\n",
      "Iteration 1120, cv error=0.250178106436, train error=0.156437545514\n",
      "Iteration 1121, cv error=0.249896153436, train error=0.156208586042\n",
      "Iteration 1122, cv error=0.249614875151, train error=0.155980188261\n",
      "Iteration 1123, cv error=0.249334269319, train error=0.155752350349\n",
      "Iteration 1124, cv error=0.249054333686, train error=0.155525070492\n",
      "Iteration 1125, cv error=0.248775066008, train error=0.155298346883\n",
      "Iteration 1126, cv error=0.248496464046, train error=0.155072177722\n",
      "Iteration 1127, cv error=0.248218525573, train error=0.154846561218\n",
      "Iteration 1128, cv error=0.247941248369, train error=0.154621495584\n",
      "Iteration 1129, cv error=0.247664630223, train error=0.154396979043\n",
      "Iteration 1130, cv error=0.247388668932, train error=0.154173009825\n",
      "Iteration 1131, cv error=0.247113362302, train error=0.153949586166\n",
      "Iteration 1132, cv error=0.246838708146, train error=0.15372670631\n",
      "Iteration 1133, cv error=0.246564704288, train error=0.153504368508\n",
      "Iteration 1134, cv error=0.246291348556, train error=0.153282571017\n",
      "Iteration 1135, cv error=0.246018638792, train error=0.153061312101\n",
      "Iteration 1136, cv error=0.245746572841, train error=0.152840590033\n",
      "Iteration 1137, cv error=0.245475148559, train error=0.152620403091\n",
      "Iteration 1138, cv error=0.24520436381, train error=0.15240074956\n",
      "Iteration 1139, cv error=0.244934216467, train error=0.152181627733\n",
      "Iteration 1140, cv error=0.244664704408, train error=0.151963035907\n",
      "Iteration 1141, cv error=0.244395825523, train error=0.151744972389\n",
      "Iteration 1142, cv error=0.244127577707, train error=0.15152743549\n",
      "Iteration 1143, cv error=0.243859958866, train error=0.15131042353\n",
      "Iteration 1144, cv error=0.243592966912, train error=0.151093934835\n",
      "Iteration 1145, cv error=0.243326599764, train error=0.150877967735\n",
      "Iteration 1146, cv error=0.243060855353, train error=0.150662520569\n",
      "Iteration 1147, cv error=0.242795731615, train error=0.150447591683\n",
      "Iteration 1148, cv error=0.242531226493, train error=0.150233179428\n",
      "Iteration 1149, cv error=0.242267337942, train error=0.150019282162\n",
      "Iteration 1150, cv error=0.242004063921, train error=0.149805898249\n",
      "Iteration 1151, cv error=0.241741402398, train error=0.149593026059\n",
      "Iteration 1152, cv error=0.241479351351, train error=0.149380663969\n",
      "Iteration 1153, cv error=0.241217908762, train error=0.149168810362\n",
      "Iteration 1154, cv error=0.240957072625, train error=0.148957463628\n",
      "Iteration 1155, cv error=0.240696840939, train error=0.148746622163\n",
      "Iteration 1156, cv error=0.240437211711, train error=0.148536284367\n",
      "Iteration 1157, cv error=0.240178182956, train error=0.148326448648\n",
      "Iteration 1158, cv error=0.239919752699, train error=0.148117113422\n",
      "Iteration 1159, cv error=0.239661918969, train error=0.147908277106\n",
      "Iteration 1160, cv error=0.239404679806, train error=0.147699938129\n",
      "Iteration 1161, cv error=0.239148033254, train error=0.14749209492\n",
      "Iteration 1162, cv error=0.238891977368, train error=0.147284745919\n",
      "Iteration 1163, cv error=0.23863651021, train error=0.147077889569\n",
      "Iteration 1164, cv error=0.238381629849, train error=0.146871524321\n",
      "Iteration 1165, cv error=0.23812733436, train error=0.146665648629\n",
      "Iteration 1166, cv error=0.237873621829, train error=0.146460260955\n",
      "Iteration 1167, cv error=0.237620490346, train error=0.146255359767\n",
      "Iteration 1168, cv error=0.237367938012, train error=0.146050943537\n",
      "Iteration 1169, cv error=0.237115962932, train error=0.145847010745\n",
      "Iteration 1170, cv error=0.236864563221, train error=0.145643559875\n",
      "Iteration 1171, cv error=0.236613737, train error=0.145440589418\n",
      "Iteration 1172, cv error=0.236363482399, train error=0.145238097869\n",
      "Iteration 1173, cv error=0.236113797554, train error=0.14503608373\n",
      "Iteration 1174, cv error=0.235864680609, train error=0.144834545508\n",
      "Iteration 1175, cv error=0.235616129714, train error=0.144633481716\n",
      "Iteration 1176, cv error=0.235368143028, train error=0.144432890872\n",
      "Iteration 1177, cv error=0.235120718718, train error=0.144232771501\n",
      "Iteration 1178, cv error=0.234873854955, train error=0.144033122131\n",
      "Iteration 1179, cv error=0.234627549921, train error=0.143833941298\n",
      "Iteration 1180, cv error=0.234381801802, train error=0.143635227541\n",
      "Iteration 1181, cv error=0.234136608794, train error=0.143436979407\n",
      "Iteration 1182, cv error=0.233891969099, train error=0.143239195447\n",
      "Iteration 1183, cv error=0.233647880925, train error=0.143041874218\n",
      "Iteration 1184, cv error=0.233404342489, train error=0.14284501428\n",
      "Iteration 1185, cv error=0.233161352015, train error=0.142648614202\n",
      "Iteration 1186, cv error=0.232918907732, train error=0.142452672556\n",
      "Iteration 1187, cv error=0.232677007879, train error=0.14225718792\n",
      "Iteration 1188, cv error=0.232435650699, train error=0.142062158877\n",
      "Iteration 1189, cv error=0.232194834445, train error=0.141867584015\n",
      "Iteration 1190, cv error=0.231954557376, train error=0.141673461927\n",
      "Iteration 1191, cv error=0.231714817756, train error=0.141479791213\n",
      "Iteration 1192, cv error=0.231475613859, train error=0.141286570476\n",
      "Iteration 1193, cv error=0.231236943963, train error=0.141093798325\n",
      "Iteration 1194, cv error=0.230998806357, train error=0.140901473374\n",
      "Iteration 1195, cv error=0.230761199332, train error=0.140709594243\n",
      "Iteration 1196, cv error=0.230524121189, train error=0.140518159556\n",
      "Iteration 1197, cv error=0.230287570235, train error=0.140327167942\n",
      "Iteration 1198, cv error=0.230051544784, train error=0.140136618035\n",
      "Iteration 1199, cv error=0.229816043158, train error=0.139946508475\n",
      "Iteration 1200, cv error=0.229581063682, train error=0.139756837906\n",
      "Iteration 1201, cv error=0.229346604691, train error=0.139567604977\n",
      "Iteration 1202, cv error=0.229112664527, train error=0.139378808343\n",
      "Iteration 1203, cv error=0.228879241537, train error=0.139190446663\n",
      "Iteration 1204, cv error=0.228646334075, train error=0.1390025186\n",
      "Iteration 1205, cv error=0.228413940503, train error=0.138815022824\n",
      "Iteration 1206, cv error=0.228182059187, train error=0.138627958009\n",
      "Iteration 1207, cv error=0.227950688503, train error=0.138441322833\n",
      "Iteration 1208, cv error=0.22771982683, train error=0.138255115979\n",
      "Iteration 1209, cv error=0.227489472557, train error=0.138069336136\n",
      "Iteration 1210, cv error=0.227259624077, train error=0.137883981997\n",
      "Iteration 1211, cv error=0.227030279791, train error=0.137699052259\n",
      "Iteration 1212, cv error=0.226801438105, train error=0.137514545626\n",
      "Iteration 1213, cv error=0.226573097433, train error=0.137330460804\n",
      "Iteration 1214, cv error=0.226345256195, train error=0.137146796504\n",
      "Iteration 1215, cv error=0.226117912817, train error=0.136963551445\n",
      "Iteration 1216, cv error=0.225891065732, train error=0.136780724347\n",
      "Iteration 1217, cv error=0.225664713379, train error=0.136598313935\n",
      "Iteration 1218, cv error=0.225438854202, train error=0.136416318941\n",
      "Iteration 1219, cv error=0.225213486654, train error=0.136234738099\n",
      "Iteration 1220, cv error=0.224988609192, train error=0.13605357015\n",
      "Iteration 1221, cv error=0.224764220282, train error=0.135872813837\n",
      "Iteration 1222, cv error=0.224540318392, train error=0.135692467909\n",
      "Iteration 1223, cv error=0.224316902001, train error=0.135512531119\n",
      "Iteration 1224, cv error=0.22409396959, train error=0.135333002226\n",
      "Iteration 1225, cv error=0.223871519649, train error=0.135153879992\n",
      "Iteration 1226, cv error=0.223649550674, train error=0.134975163183\n",
      "Iteration 1227, cv error=0.223428061164, train error=0.134796850571\n",
      "Iteration 1228, cv error=0.223207049629, train error=0.134618940932\n",
      "Iteration 1229, cv error=0.222986514581, train error=0.134441433045\n",
      "Iteration 1230, cv error=0.222766454539, train error=0.134264325695\n",
      "Iteration 1231, cv error=0.22254686803, train error=0.134087617671\n",
      "Iteration 1232, cv error=0.222327753585, train error=0.133911307766\n",
      "Iteration 1233, cv error=0.222109109742, train error=0.133735394778\n",
      "Iteration 1234, cv error=0.221890935043, train error=0.133559877508\n",
      "Iteration 1235, cv error=0.221673228039, train error=0.133384754764\n",
      "Iteration 1236, cv error=0.221455987284, train error=0.133210025355\n",
      "Iteration 1237, cv error=0.22123921134, train error=0.133035688097\n",
      "Iteration 1238, cv error=0.221022898774, train error=0.132861741808\n",
      "Iteration 1239, cv error=0.220807048159, train error=0.132688185313\n",
      "Iteration 1240, cv error=0.220591658073, train error=0.132515017437\n",
      "Iteration 1241, cv error=0.220376727101, train error=0.132342237014\n",
      "Iteration 1242, cv error=0.220162253832, train error=0.132169842879\n",
      "Iteration 1243, cv error=0.219948236863, train error=0.131997833872\n",
      "Iteration 1244, cv error=0.219734674796, train error=0.131826208838\n",
      "Iteration 1245, cv error=0.219521566237, train error=0.131654966626\n",
      "Iteration 1246, cv error=0.219308909799, train error=0.131484106087\n",
      "Iteration 1247, cv error=0.219096704102, train error=0.131313626078\n",
      "Iteration 1248, cv error=0.218884947768, train error=0.131143525462\n",
      "Iteration 1249, cv error=0.218673639429, train error=0.130973803101\n",
      "Iteration 1250, cv error=0.218462777718, train error=0.130804457865\n",
      "Iteration 1251, cv error=0.218252361277, train error=0.130635488628\n",
      "Iteration 1252, cv error=0.218042388752, train error=0.130466894266\n",
      "Iteration 1253, cv error=0.217832858795, train error=0.130298673661\n",
      "Iteration 1254, cv error=0.217623770063, train error=0.130130825697\n",
      "Iteration 1255, cv error=0.217415121218, train error=0.129963349264\n",
      "Iteration 1256, cv error=0.217206910929, train error=0.129796243255\n",
      "Iteration 1257, cv error=0.216999137869, train error=0.129629506566\n",
      "Iteration 1258, cv error=0.216791800716, train error=0.129463138098\n",
      "Iteration 1259, cv error=0.216584898156, train error=0.129297136758\n",
      "Iteration 1260, cv error=0.216378428876, train error=0.129131501452\n",
      "Iteration 1261, cv error=0.216172391572, train error=0.128966231095\n",
      "Iteration 1262, cv error=0.215966784944, train error=0.128801324602\n",
      "Iteration 1263, cv error=0.215761607696, train error=0.128636780893\n",
      "Iteration 1264, cv error=0.21555685854, train error=0.128472598895\n",
      "Iteration 1265, cv error=0.21535253619, train error=0.128308777533\n",
      "Iteration 1266, cv error=0.215148639367, train error=0.128145315741\n",
      "Iteration 1267, cv error=0.214945166797, train error=0.127982212454\n",
      "Iteration 1268, cv error=0.214742117211, train error=0.127819466611\n",
      "Iteration 1269, cv error=0.214539489345, train error=0.127657077157\n",
      "Iteration 1270, cv error=0.21433728194, train error=0.127495043037\n",
      "Iteration 1271, cv error=0.214135493742, train error=0.127333363203\n",
      "Iteration 1272, cv error=0.213934123501, train error=0.127172036609\n",
      "Iteration 1273, cv error=0.213733169975, train error=0.127011062214\n",
      "Iteration 1274, cv error=0.213532631923, train error=0.12685043898\n",
      "Iteration 1275, cv error=0.213332508113, train error=0.126690165872\n",
      "Iteration 1276, cv error=0.213132797314, train error=0.126530241859\n",
      "Iteration 1277, cv error=0.212933498303, train error=0.126370665915\n",
      "Iteration 1278, cv error=0.21273460986, train error=0.126211437016\n",
      "Iteration 1279, cv error=0.212536130771, train error=0.126052554142\n",
      "Iteration 1280, cv error=0.212338059825, train error=0.125894016278\n",
      "Iteration 1281, cv error=0.212140395819, train error=0.125735822411\n",
      "Iteration 1282, cv error=0.211943137551, train error=0.125577971531\n",
      "Iteration 1283, cv error=0.211746283827, train error=0.125420462634\n",
      "Iteration 1284, cv error=0.211549833456, train error=0.125263294718\n",
      "Iteration 1285, cv error=0.211353785252, train error=0.125106466785\n",
      "Iteration 1286, cv error=0.211158138033, train error=0.124949977839\n",
      "Iteration 1287, cv error=0.210962890622, train error=0.12479382689\n",
      "Iteration 1288, cv error=0.210768041849, train error=0.12463801295\n",
      "Iteration 1289, cv error=0.210573590545, train error=0.124482535034\n",
      "Iteration 1290, cv error=0.210379535548, train error=0.124327392163\n",
      "Iteration 1291, cv error=0.210185875699, train error=0.124172583358\n",
      "Iteration 1292, cv error=0.209992609845, train error=0.124018107647\n",
      "Iteration 1293, cv error=0.209799736836, train error=0.123863964058\n",
      "Iteration 1294, cv error=0.209607255529, train error=0.123710151625\n",
      "Iteration 1295, cv error=0.209415164781, train error=0.123556669384\n",
      "Iteration 1296, cv error=0.209223463459, train error=0.123403516375\n",
      "Iteration 1297, cv error=0.209032150431, train error=0.123250691642\n",
      "Iteration 1298, cv error=0.208841224569, train error=0.123098194231\n",
      "Iteration 1299, cv error=0.208650684751, train error=0.122946023191\n",
      "Iteration 1300, cv error=0.208460529859, train error=0.122794177577\n",
      "Iteration 1301, cv error=0.208270758779, train error=0.122642656445\n",
      "Iteration 1302, cv error=0.208081370402, train error=0.122491458854\n",
      "Iteration 1303, cv error=0.207892363623, train error=0.122340583869\n",
      "Iteration 1304, cv error=0.20770373734, train error=0.122190030556\n",
      "Iteration 1305, cv error=0.207515490457, train error=0.122039797984\n",
      "Iteration 1306, cv error=0.207327621882, train error=0.121889885227\n",
      "Iteration 1307, cv error=0.207140130526, train error=0.121740291361\n",
      "Iteration 1308, cv error=0.206953015305, train error=0.121591015466\n",
      "Iteration 1309, cv error=0.20676627514, train error=0.121442056624\n",
      "Iteration 1310, cv error=0.206579908954, train error=0.121293413922\n",
      "Iteration 1311, cv error=0.206393915677, train error=0.121145086449\n",
      "Iteration 1312, cv error=0.206208294241, train error=0.120997073298\n",
      "Iteration 1313, cv error=0.206023043582, train error=0.120849373563\n",
      "Iteration 1314, cv error=0.205838162641, train error=0.120701986344\n",
      "Iteration 1315, cv error=0.205653650363, train error=0.120554910743\n",
      "Iteration 1316, cv error=0.205469505697, train error=0.120408145864\n",
      "Iteration 1317, cv error=0.205285727596, train error=0.120261690817\n",
      "Iteration 1318, cv error=0.205102315016, train error=0.120115544711\n",
      "Iteration 1319, cv error=0.204919266918, train error=0.119969706663\n",
      "Iteration 1320, cv error=0.204736582267, train error=0.119824175789\n",
      "Iteration 1321, cv error=0.204554260031, train error=0.119678951209\n",
      "Iteration 1322, cv error=0.204372299184, train error=0.119534032049\n",
      "Iteration 1323, cv error=0.204190698701, train error=0.119389417433\n",
      "Iteration 1324, cv error=0.204009457562, train error=0.119245106492\n",
      "Iteration 1325, cv error=0.203828574753, train error=0.11910109836\n",
      "Iteration 1326, cv error=0.203648049261, train error=0.11895739217\n",
      "Iteration 1327, cv error=0.203467880077, train error=0.118813987064\n",
      "Iteration 1328, cv error=0.203288066198, train error=0.118670882181\n",
      "Iteration 1329, cv error=0.203108606623, train error=0.118528076667\n",
      "Iteration 1330, cv error=0.202929500354, train error=0.118385569671\n",
      "Iteration 1331, cv error=0.202750746399, train error=0.118243360341\n",
      "Iteration 1332, cv error=0.202572343769, train error=0.118101447833\n",
      "Iteration 1333, cv error=0.202394291477, train error=0.117959831303\n",
      "Iteration 1334, cv error=0.202216588541, train error=0.11781850991\n",
      "Iteration 1335, cv error=0.202039233984, train error=0.117677482816\n",
      "Iteration 1336, cv error=0.20186222683, train error=0.117536749188\n",
      "Iteration 1337, cv error=0.201685566109, train error=0.117396308193\n",
      "Iteration 1338, cv error=0.201509250852, train error=0.117256159002\n",
      "Iteration 1339, cv error=0.201333280096, train error=0.11711630079\n",
      "Iteration 1340, cv error=0.201157652881, train error=0.116976732733\n",
      "Iteration 1341, cv error=0.20098236825, train error=0.116837454011\n",
      "Iteration 1342, cv error=0.200807425249, train error=0.116698463807\n",
      "Iteration 1343, cv error=0.200632822929, train error=0.116559761305\n",
      "Iteration 1344, cv error=0.200458560344, train error=0.116421345694\n",
      "Iteration 1345, cv error=0.20028463655, train error=0.116283216165\n",
      "Iteration 1346, cv error=0.200111050609, train error=0.116145371912\n",
      "Iteration 1347, cv error=0.199937801585, train error=0.11600781213\n",
      "Iteration 1348, cv error=0.199764888545, train error=0.11587053602\n",
      "Iteration 1349, cv error=0.19959231056, train error=0.115733542784\n",
      "Iteration 1350, cv error=0.199420066706, train error=0.115596831626\n",
      "Iteration 1351, cv error=0.199248156058, train error=0.115460401753\n",
      "Iteration 1352, cv error=0.1990765777, train error=0.115324252376\n",
      "Iteration 1353, cv error=0.198905330715, train error=0.115188382709\n",
      "Iteration 1354, cv error=0.198734414191, train error=0.115052791966\n",
      "Iteration 1355, cv error=0.198563827219, train error=0.114917479366\n",
      "Iteration 1356, cv error=0.198393568893, train error=0.11478244413\n",
      "Iteration 1357, cv error=0.198223638313, train error=0.114647685481\n",
      "Iteration 1358, cv error=0.198054034577, train error=0.114513202647\n",
      "Iteration 1359, cv error=0.197884756792, train error=0.114378994855\n",
      "Iteration 1360, cv error=0.197715804063, train error=0.114245061339\n",
      "Iteration 1361, cv error=0.197547175503, train error=0.114111401331\n",
      "Iteration 1362, cv error=0.197378870224, train error=0.113978014069\n",
      "Iteration 1363, cv error=0.197210887344, train error=0.113844898793\n",
      "Iteration 1364, cv error=0.197043225984, train error=0.113712054744\n",
      "Iteration 1365, cv error=0.196875885266, train error=0.113579481167\n",
      "Iteration 1366, cv error=0.196708864317, train error=0.11344717731\n",
      "Iteration 1367, cv error=0.196542162267, train error=0.113315142422\n",
      "Iteration 1368, cv error=0.196375778249, train error=0.113183375755\n",
      "Iteration 1369, cv error=0.196209711399, train error=0.113051876566\n",
      "Iteration 1370, cv error=0.196043960855, train error=0.11292064411\n",
      "Iteration 1371, cv error=0.19587852576, train error=0.112789677648\n",
      "Iteration 1372, cv error=0.195713405258, train error=0.112658976444\n",
      "Iteration 1373, cv error=0.195548598498, train error=0.11252853976\n",
      "Iteration 1374, cv error=0.195384104632, train error=0.112398366867\n",
      "Iteration 1375, cv error=0.195219922812, train error=0.112268457032\n",
      "Iteration 1376, cv error=0.195056052197, train error=0.112138809529\n",
      "Iteration 1377, cv error=0.194892491947, train error=0.112009423633\n",
      "Iteration 1378, cv error=0.194729241224, train error=0.11188029862\n",
      "Iteration 1379, cv error=0.194566299195, train error=0.111751433772\n",
      "Iteration 1380, cv error=0.194403665028, train error=0.111622828371\n",
      "Iteration 1381, cv error=0.194241337896, train error=0.1114944817\n",
      "Iteration 1382, cv error=0.194079316974, train error=0.111366393048\n",
      "Iteration 1383, cv error=0.193917601438, train error=0.111238561703\n",
      "Iteration 1384, cv error=0.193756190471, train error=0.111110986958\n",
      "Iteration 1385, cv error=0.193595083254, train error=0.110983668108\n",
      "Iteration 1386, cv error=0.193434278975, train error=0.110856604448\n",
      "Iteration 1387, cv error=0.193273776823, train error=0.110729795279\n",
      "Iteration 1388, cv error=0.193113575989, train error=0.110603239901\n",
      "Iteration 1389, cv error=0.192953675668, train error=0.110476937618\n",
      "Iteration 1390, cv error=0.192794075059, train error=0.110350887738\n",
      "Iteration 1391, cv error=0.192634773361, train error=0.110225089567\n",
      "Iteration 1392, cv error=0.192475769777, train error=0.110099542418\n",
      "Iteration 1393, cv error=0.192317063514, train error=0.109974245603\n",
      "Iteration 1394, cv error=0.19215865378, train error=0.109849198437\n",
      "Iteration 1395, cv error=0.192000539787, train error=0.109724400239\n",
      "Iteration 1396, cv error=0.191842720748, train error=0.109599850329\n",
      "Iteration 1397, cv error=0.191685195881, train error=0.109475548029\n",
      "Iteration 1398, cv error=0.191527964405, train error=0.109351492664\n",
      "Iteration 1399, cv error=0.191371025542, train error=0.10922768356\n",
      "Iteration 1400, cv error=0.191214378516, train error=0.109104120047\n",
      "Iteration 1401, cv error=0.191058022557, train error=0.108980801456\n",
      "Iteration 1402, cv error=0.190901956893, train error=0.108857727121\n",
      "Iteration 1403, cv error=0.190746180759, train error=0.108734896378\n",
      "Iteration 1404, cv error=0.190590693388, train error=0.108612308565\n",
      "Iteration 1405, cv error=0.190435494019, train error=0.108489963022\n",
      "Iteration 1406, cv error=0.190280581893, train error=0.108367859092\n",
      "Iteration 1407, cv error=0.190125956253, train error=0.108245996119\n",
      "Iteration 1408, cv error=0.189971616345, train error=0.108124373451\n",
      "Iteration 1409, cv error=0.189817561417, train error=0.108002990436\n",
      "Iteration 1410, cv error=0.189663790721, train error=0.107881846426\n",
      "Iteration 1411, cv error=0.189510303509, train error=0.107760940774\n",
      "Iteration 1412, cv error=0.189357099037, train error=0.107640272837\n",
      "Iteration 1413, cv error=0.189204176565, train error=0.10751984197\n",
      "Iteration 1414, cv error=0.189051535353, train error=0.107399647536\n",
      "Iteration 1415, cv error=0.188899174665, train error=0.107279688894\n",
      "Iteration 1416, cv error=0.188747093766, train error=0.10715996541\n",
      "Iteration 1417, cv error=0.188595291926, train error=0.107040476451\n",
      "Iteration 1418, cv error=0.188443768415, train error=0.106921221383\n",
      "Iteration 1419, cv error=0.188292522506, train error=0.106802199578\n",
      "Iteration 1420, cv error=0.188141553476, train error=0.106683410408\n",
      "Iteration 1421, cv error=0.187990860602, train error=0.106564853248\n",
      "Iteration 1422, cv error=0.187840443166, train error=0.106446527474\n",
      "Iteration 1423, cv error=0.187690300449, train error=0.106328432466\n",
      "Iteration 1424, cv error=0.187540431739, train error=0.106210567603\n",
      "Iteration 1425, cv error=0.187390836322, train error=0.10609293227\n",
      "Iteration 1426, cv error=0.187241513489, train error=0.10597552585\n",
      "Iteration 1427, cv error=0.187092462533, train error=0.105858347731\n",
      "Iteration 1428, cv error=0.186943682748, train error=0.105741397302\n",
      "Iteration 1429, cv error=0.186795173432, train error=0.105624673954\n",
      "Iteration 1430, cv error=0.186646933884, train error=0.105508177079\n",
      "Iteration 1431, cv error=0.186498963406, train error=0.105391906073\n",
      "Iteration 1432, cv error=0.186351261303, train error=0.105275860333\n",
      "Iteration 1433, cv error=0.186203826881, train error=0.105160039257\n",
      "Iteration 1434, cv error=0.186056659449, train error=0.105044442247\n",
      "Iteration 1435, cv error=0.185909758318, train error=0.104929068706\n",
      "Iteration 1436, cv error=0.185763122801, train error=0.104813918038\n",
      "Iteration 1437, cv error=0.185616752215, train error=0.104698989651\n",
      "Iteration 1438, cv error=0.185470645876, train error=0.104584282952\n",
      "Iteration 1439, cv error=0.185324803106, train error=0.104469797354\n",
      "Iteration 1440, cv error=0.185179223226, train error=0.104355532268\n",
      "Iteration 1441, cv error=0.185033905562, train error=0.104241487109\n",
      "Iteration 1442, cv error=0.184888849439, train error=0.104127661294\n",
      "Iteration 1443, cv error=0.184744054188, train error=0.104014054241\n",
      "Iteration 1444, cv error=0.184599519139, train error=0.103900665371\n",
      "Iteration 1445, cv error=0.184455243625, train error=0.103787494106\n",
      "Iteration 1446, cv error=0.184311226983, train error=0.103674539869\n",
      "Iteration 1447, cv error=0.18416746855, train error=0.103561802088\n",
      "Iteration 1448, cv error=0.184023967665, train error=0.103449280189\n",
      "Iteration 1449, cv error=0.183880723672, train error=0.103336973603\n",
      "Iteration 1450, cv error=0.183737735914, train error=0.103224881761\n",
      "Iteration 1451, cv error=0.183595003738, train error=0.103113004097\n",
      "Iteration 1452, cv error=0.183452526491, train error=0.103001340047\n",
      "Iteration 1453, cv error=0.183310303525, train error=0.102889889046\n",
      "Iteration 1454, cv error=0.183168334192, train error=0.102778650535\n",
      "Iteration 1455, cv error=0.183026617847, train error=0.102667623954\n",
      "Iteration 1456, cv error=0.182885153846, train error=0.102556808746\n",
      "Iteration 1457, cv error=0.18274394155, train error=0.102446204356\n",
      "Iteration 1458, cv error=0.182602980318, train error=0.102335810229\n",
      "Iteration 1459, cv error=0.182462269513, train error=0.102225625814\n",
      "Iteration 1460, cv error=0.182321808502, train error=0.10211565056\n",
      "Iteration 1461, cv error=0.18218159665, train error=0.10200588392\n",
      "Iteration 1462, cv error=0.182041633327, train error=0.101896325347\n",
      "Iteration 1463, cv error=0.181901917905, train error=0.101786974296\n",
      "Iteration 1464, cv error=0.181762449756, train error=0.101677830224\n",
      "Iteration 1465, cv error=0.181623228255, train error=0.101568892589\n",
      "Iteration 1466, cv error=0.181484252781, train error=0.101460160853\n",
      "Iteration 1467, cv error=0.181345522711, train error=0.101351634477\n",
      "Iteration 1468, cv error=0.181207037428, train error=0.101243312926\n",
      "Iteration 1469, cv error=0.181068796314, train error=0.101135195666\n",
      "Iteration 1470, cv error=0.180930798754, train error=0.101027282163\n",
      "Iteration 1471, cv error=0.180793044136, train error=0.100919571887\n",
      "Iteration 1472, cv error=0.180655531849, train error=0.100812064309\n",
      "Iteration 1473, cv error=0.180518261284, train error=0.100704758901\n",
      "Iteration 1474, cv error=0.180381231832, train error=0.100597655138\n",
      "Iteration 1475, cv error=0.180244442891, train error=0.100490752496\n",
      "Iteration 1476, cv error=0.180107893855, train error=0.100384050453\n",
      "Iteration 1477, cv error=0.179971584124, train error=0.100277548487\n",
      "Iteration 1478, cv error=0.179835513098, train error=0.10017124608\n",
      "Iteration 1479, cv error=0.17969968018, train error=0.100065142715\n",
      "Iteration 1480, cv error=0.179564084774, train error=0.0999592378758\n",
      "Iteration 1481, cv error=0.179428726287, train error=0.0998535310488\n",
      "Iteration 1482, cv error=0.179293604126, train error=0.0997480217215\n",
      "Iteration 1483, cv error=0.179158717701, train error=0.0996427093834\n",
      "Iteration 1484, cv error=0.179024066424, train error=0.0995375935253\n",
      "Iteration 1485, cv error=0.17888964971, train error=0.09943267364\n",
      "Iteration 1486, cv error=0.178755466973, train error=0.0993279492217\n",
      "Iteration 1487, cv error=0.17862151763, train error=0.0992234197662\n",
      "Iteration 1488, cv error=0.178487801102, train error=0.099119084771\n",
      "Iteration 1489, cv error=0.178354316808, train error=0.0990149437352\n",
      "Iteration 1490, cv error=0.178221064173, train error=0.0989109961595\n",
      "Iteration 1491, cv error=0.178088042619, train error=0.0988072415463\n",
      "Iteration 1492, cv error=0.177955251575, train error=0.0987036793992\n",
      "Iteration 1493, cv error=0.177822690467, train error=0.098600309224\n",
      "Iteration 1494, cv error=0.177690358726, train error=0.0984971305275\n",
      "Iteration 1495, cv error=0.177558255784, train error=0.0983941428184\n",
      "Iteration 1496, cv error=0.177426381075, train error=0.0982913456069\n",
      "Iteration 1497, cv error=0.177294734032, train error=0.0981887384047\n",
      "Iteration 1498, cv error=0.177163314095, train error=0.0980863207252\n",
      "Iteration 1499, cv error=0.177032120701, train error=0.0979840920831\n",
      "Iteration 1500, cv error=0.176901153291, train error=0.097882051995\n",
      "Iteration 1501, cv error=0.176770411307, train error=0.0977801999787\n",
      "Iteration 1502, cv error=0.176639894194, train error=0.0976785355537\n",
      "Iteration 1503, cv error=0.176509601396, train error=0.0975770582411\n",
      "Iteration 1504, cv error=0.176379532362, train error=0.0974757675632\n",
      "Iteration 1505, cv error=0.176249686541, train error=0.0973746630443\n",
      "Iteration 1506, cv error=0.176120063383, train error=0.0972737442097\n",
      "Iteration 1507, cv error=0.175990662342, train error=0.0971730105866\n",
      "Iteration 1508, cv error=0.17586148287, train error=0.0970724617035\n",
      "Iteration 1509, cv error=0.175732524425, train error=0.0969720970905\n",
      "Iteration 1510, cv error=0.175603786464, train error=0.0968719162791\n",
      "Iteration 1511, cv error=0.175475268446, train error=0.0967719188023\n",
      "Iteration 1512, cv error=0.175346969832, train error=0.0966721041947\n",
      "Iteration 1513, cv error=0.175218890084, train error=0.0965724719921\n",
      "Iteration 1514, cv error=0.175091028668, train error=0.096473021732\n",
      "Iteration 1515, cv error=0.174963385048, train error=0.0963737529533\n",
      "Iteration 1516, cv error=0.174835958693, train error=0.0962746651964\n",
      "Iteration 1517, cv error=0.174708749071, train error=0.0961757580031\n",
      "Iteration 1518, cv error=0.174581755653, train error=0.0960770309165\n",
      "Iteration 1519, cv error=0.174454977912, train error=0.0959784834814\n",
      "Iteration 1520, cv error=0.174328415322, train error=0.095880115244\n",
      "Iteration 1521, cv error=0.174202067358, train error=0.0957819257517\n",
      "Iteration 1522, cv error=0.174075933498, train error=0.0956839145536\n",
      "Iteration 1523, cv error=0.17395001322, train error=0.0955860811999\n",
      "Iteration 1524, cv error=0.173824306005, train error=0.0954884252427\n",
      "Iteration 1525, cv error=0.173698811335, train error=0.0953909462349\n",
      "Iteration 1526, cv error=0.173573528693, train error=0.0952936437313\n",
      "Iteration 1527, cv error=0.173448457564, train error=0.0951965172879\n",
      "Iteration 1528, cv error=0.173323597436, train error=0.0950995664621\n",
      "Iteration 1529, cv error=0.173198947796, train error=0.0950027908127\n",
      "Iteration 1530, cv error=0.173074508135, train error=0.0949061898998\n",
      "Iteration 1531, cv error=0.172950277943, train error=0.0948097632851\n",
      "Iteration 1532, cv error=0.172826256713, train error=0.0947135105314\n",
      "Iteration 1533, cv error=0.17270244394, train error=0.094617431203\n",
      "Iteration 1534, cv error=0.172578839121, train error=0.0945215248656\n",
      "Iteration 1535, cv error=0.172455441752, train error=0.0944257910863\n",
      "Iteration 1536, cv error=0.172332251332, train error=0.0943302294334\n",
      "Iteration 1537, cv error=0.172209267362, train error=0.0942348394765\n",
      "Iteration 1538, cv error=0.172086489344, train error=0.0941396207869\n",
      "Iteration 1539, cv error=0.171963916782, train error=0.0940445729368\n",
      "Iteration 1540, cv error=0.17184154918, train error=0.0939496955\n",
      "Iteration 1541, cv error=0.171719386046, train error=0.0938549880516\n",
      "Iteration 1542, cv error=0.171597426886, train error=0.0937604501679\n",
      "Iteration 1543, cv error=0.171475671211, train error=0.0936660814266\n",
      "Iteration 1544, cv error=0.171354118532, train error=0.0935718814069\n",
      "Iteration 1545, cv error=0.17123276836, train error=0.0934778496889\n",
      "Iteration 1546, cv error=0.171111620211, train error=0.0933839858543\n",
      "Iteration 1547, cv error=0.170990673598, train error=0.093290289486\n",
      "Iteration 1548, cv error=0.17086992804, train error=0.0931967601684\n",
      "Iteration 1549, cv error=0.170749383053, train error=0.0931033974868\n",
      "Iteration 1550, cv error=0.170629038159, train error=0.0930102010281\n",
      "Iteration 1551, cv error=0.170508892878, train error=0.0929171703803\n",
      "Iteration 1552, cv error=0.170388946732, train error=0.0928243051329\n",
      "Iteration 1553, cv error=0.170269199246, train error=0.0927316048764\n",
      "Iteration 1554, cv error=0.170149649945, train error=0.0926390692027\n",
      "Iteration 1555, cv error=0.170030298356, train error=0.092546697705\n",
      "Iteration 1556, cv error=0.169911144007, train error=0.0924544899777\n",
      "Iteration 1557, cv error=0.169792186427, train error=0.0923624456165\n",
      "Iteration 1558, cv error=0.169673425149, train error=0.0922705642183\n",
      "Iteration 1559, cv error=0.169554859703, train error=0.0921788453812\n",
      "Iteration 1560, cv error=0.169436489625, train error=0.0920872887047\n",
      "Iteration 1561, cv error=0.169318314449, train error=0.0919958937894\n",
      "Iteration 1562, cv error=0.169200333712, train error=0.0919046602371\n",
      "Iteration 1563, cv error=0.169082546951, train error=0.0918135876509\n",
      "Iteration 1564, cv error=0.168964953707, train error=0.0917226756352\n",
      "Iteration 1565, cv error=0.168847553519, train error=0.0916319237955\n",
      "Iteration 1566, cv error=0.168730345931, train error=0.0915413317385\n",
      "Iteration 1567, cv error=0.168613330484, train error=0.0914508990722\n",
      "Iteration 1568, cv error=0.168496506725, train error=0.0913606254057\n",
      "Iteration 1569, cv error=0.168379874199, train error=0.0912705103494\n",
      "Iteration 1570, cv error=0.168263432454, train error=0.0911805535148\n",
      "Iteration 1571, cv error=0.168147181038, train error=0.0910907545148\n",
      "Iteration 1572, cv error=0.168031119502, train error=0.0910011129631\n",
      "Iteration 1573, cv error=0.167915247397, train error=0.090911628475\n",
      "Iteration 1574, cv error=0.167799564276, train error=0.0908223006667\n",
      "Iteration 1575, cv error=0.167684069693, train error=0.0907331291557\n",
      "Iteration 1576, cv error=0.167568763204, train error=0.0906441135606\n",
      "Iteration 1577, cv error=0.167453644364, train error=0.0905552535012\n",
      "Iteration 1578, cv error=0.167338712733, train error=0.0904665485986\n",
      "Iteration 1579, cv error=0.167223967869, train error=0.0903779984747\n",
      "Iteration 1580, cv error=0.167109409333, train error=0.0902896027529\n",
      "Iteration 1581, cv error=0.166995036687, train error=0.0902013610577\n",
      "Iteration 1582, cv error=0.166880849494, train error=0.0901132730145\n",
      "Iteration 1583, cv error=0.166766847319, train error=0.0900253382501\n",
      "Iteration 1584, cv error=0.166653029728, train error=0.0899375563924\n",
      "Iteration 1585, cv error=0.166539396287, train error=0.0898499270702\n",
      "Iteration 1586, cv error=0.166425946564, train error=0.0897624499138\n",
      "Iteration 1587, cv error=0.16631268013, train error=0.0896751245544\n",
      "Iteration 1588, cv error=0.166199596556, train error=0.0895879506243\n",
      "Iteration 1589, cv error=0.166086695412, train error=0.0895009277569\n",
      "Iteration 1590, cv error=0.165973976273, train error=0.089414055587\n",
      "Iteration 1591, cv error=0.165861438713, train error=0.0893273337501\n",
      "Iteration 1592, cv error=0.165749082308, train error=0.089240761883\n",
      "Iteration 1593, cv error=0.165636906635, train error=0.0891543396237\n",
      "Iteration 1594, cv error=0.165524911272, train error=0.0890680666112\n",
      "Iteration 1595, cv error=0.165413095799, train error=0.0889819424855\n",
      "Iteration 1596, cv error=0.165301459797, train error=0.0888959668879\n",
      "Iteration 1597, cv error=0.165190002847, train error=0.0888101394605\n",
      "Iteration 1598, cv error=0.165078724533, train error=0.0887244598467\n",
      "Iteration 1599, cv error=0.164967624438, train error=0.0886389276911\n",
      "Iteration 1600, cv error=0.16485670215, train error=0.0885535426389\n",
      "Iteration 1601, cv error=0.164745957254, train error=0.0884683043369\n",
      "Iteration 1602, cv error=0.164635389338, train error=0.0883832124326\n",
      "Iteration 1603, cv error=0.164524997992, train error=0.0882982665748\n",
      "Iteration 1604, cv error=0.164414782805, train error=0.0882134664132\n",
      "Iteration 1605, cv error=0.164304743371, train error=0.0881288115986\n",
      "Iteration 1606, cv error=0.16419487928, train error=0.0880443017828\n",
      "Iteration 1607, cv error=0.164085190128, train error=0.0879599366188\n",
      "Iteration 1608, cv error=0.16397567551, train error=0.0878757157606\n",
      "Iteration 1609, cv error=0.163866335021, train error=0.087791638863\n",
      "Iteration 1610, cv error=0.163757168259, train error=0.0877077055822\n",
      "Iteration 1611, cv error=0.163648174823, train error=0.0876239155752\n",
      "Iteration 1612, cv error=0.163539354312, train error=0.0875402685001\n",
      "Iteration 1613, cv error=0.163430706328, train error=0.087456764016\n",
      "Iteration 1614, cv error=0.163322230472, train error=0.0873734017831\n",
      "Iteration 1615, cv error=0.163213926347, train error=0.0872901814624\n",
      "Iteration 1616, cv error=0.163105793559, train error=0.0872071027162\n",
      "Iteration 1617, cv error=0.162997831713, train error=0.0871241652077\n",
      "Iteration 1618, cv error=0.162890040414, train error=0.087041368601\n",
      "Iteration 1619, cv error=0.162782419272, train error=0.0869587125613\n",
      "Iteration 1620, cv error=0.162674967894, train error=0.0868761967548\n",
      "Iteration 1621, cv error=0.162567685892, train error=0.0867938208488\n",
      "Iteration 1622, cv error=0.162460572875, train error=0.0867115845113\n",
      "Iteration 1623, cv error=0.162353628457, train error=0.0866294874116\n",
      "Iteration 1624, cv error=0.162246852251, train error=0.0865475292197\n",
      "Iteration 1625, cv error=0.16214024387, train error=0.086465709607\n",
      "Iteration 1626, cv error=0.162033802932, train error=0.0863840282454\n",
      "Iteration 1627, cv error=0.161927529051, train error=0.0863024848081\n",
      "Iteration 1628, cv error=0.161821421848, train error=0.0862210789691\n",
      "Iteration 1629, cv error=0.161715480939, train error=0.0861398104035\n",
      "Iteration 1630, cv error=0.161609705945, train error=0.0860586787873\n",
      "Iteration 1631, cv error=0.161504096488, train error=0.0859776837975\n",
      "Iteration 1632, cv error=0.161398652188, train error=0.0858968251119\n",
      "Iteration 1633, cv error=0.161293372671, train error=0.0858161024094\n",
      "Iteration 1634, cv error=0.161188257559, train error=0.08573551537\n",
      "Iteration 1635, cv error=0.161083306479, train error=0.0856550636743\n",
      "Iteration 1636, cv error=0.160978519056, train error=0.0855747470041\n",
      "Iteration 1637, cv error=0.160873894918, train error=0.0854945650421\n",
      "Iteration 1638, cv error=0.160769433694, train error=0.0854145174718\n",
      "Iteration 1639, cv error=0.160665135013, train error=0.0853346039779\n",
      "Iteration 1640, cv error=0.160560998507, train error=0.0852548242457\n",
      "Iteration 1641, cv error=0.160457023806, train error=0.0851751779617\n",
      "Iteration 1642, cv error=0.160353210544, train error=0.0850956648133\n",
      "Iteration 1643, cv error=0.160249558354, train error=0.0850162844887\n",
      "Iteration 1644, cv error=0.160146066872, train error=0.084937036677\n",
      "Iteration 1645, cv error=0.160042735733, train error=0.0848579210684\n",
      "Iteration 1646, cv error=0.159939564573, train error=0.0847789373538\n",
      "Iteration 1647, cv error=0.159836553032, train error=0.0847000852252\n",
      "Iteration 1648, cv error=0.159733700748, train error=0.0846213643754\n",
      "Iteration 1649, cv error=0.159631007361, train error=0.084542774498\n",
      "Iteration 1650, cv error=0.159528472513, train error=0.0844643152879\n",
      "Iteration 1651, cv error=0.159426095844, train error=0.0843859864403\n",
      "Iteration 1652, cv error=0.159323876999, train error=0.0843077876519\n",
      "Iteration 1653, cv error=0.159221815621, train error=0.0842297186198\n",
      "Iteration 1654, cv error=0.159119911356, train error=0.0841517790423\n",
      "Iteration 1655, cv error=0.159018163849, train error=0.0840739686185\n",
      "Iteration 1656, cv error=0.158916572748, train error=0.0839962870483\n",
      "Iteration 1657, cv error=0.158815137701, train error=0.0839187340325\n",
      "Iteration 1658, cv error=0.158713858356, train error=0.0838413092729\n",
      "Iteration 1659, cv error=0.158612734364, train error=0.0837640124721\n",
      "Iteration 1660, cv error=0.158511765377, train error=0.0836868433335\n",
      "Iteration 1661, cv error=0.158410951045, train error=0.0836098015615\n",
      "Iteration 1662, cv error=0.158310291022, train error=0.0835328868612\n",
      "Iteration 1663, cv error=0.158209784963, train error=0.0834560989387\n",
      "Iteration 1664, cv error=0.158109432521, train error=0.0833794375009\n",
      "Iteration 1665, cv error=0.158009233354, train error=0.0833029022555\n",
      "Iteration 1666, cv error=0.157909187117, train error=0.0832264929112\n",
      "Iteration 1667, cv error=0.15780929347, train error=0.0831502091775\n",
      "Iteration 1668, cv error=0.15770955207, train error=0.0830740507646\n",
      "Iteration 1669, cv error=0.157609962577, train error=0.0829980173837\n",
      "Iteration 1670, cv error=0.157510524653, train error=0.0829221087469\n",
      "Iteration 1671, cv error=0.157411237958, train error=0.0828463245668\n",
      "Iteration 1672, cv error=0.157312102156, train error=0.0827706645572\n",
      "Iteration 1673, cv error=0.157213116911, train error=0.0826951284327\n",
      "Iteration 1674, cv error=0.157114281886, train error=0.0826197159084\n",
      "Iteration 1675, cv error=0.157015596747, train error=0.0825444267006\n",
      "Iteration 1676, cv error=0.156917061161, train error=0.0824692605262\n",
      "Iteration 1677, cv error=0.156818674795, train error=0.0823942171031\n",
      "Iteration 1678, cv error=0.156720437318, train error=0.0823192961498\n",
      "Iteration 1679, cv error=0.156622348398, train error=0.0822444973858\n",
      "Iteration 1680, cv error=0.156524407706, train error=0.0821698205312\n",
      "Iteration 1681, cv error=0.156426614912, train error=0.0820952653073\n",
      "Iteration 1682, cv error=0.15632896969, train error=0.0820208314357\n",
      "Iteration 1683, cv error=0.156231471711, train error=0.0819465186392\n",
      "Iteration 1684, cv error=0.15613412065, train error=0.0818723266412\n",
      "Iteration 1685, cv error=0.15603691618, train error=0.081798255166\n",
      "Iteration 1686, cv error=0.155939857979, train error=0.0817243039386\n",
      "Iteration 1687, cv error=0.155842945723, train error=0.0816504726849\n",
      "Iteration 1688, cv error=0.155746179088, train error=0.0815767611314\n",
      "Iteration 1689, cv error=0.155649557753, train error=0.0815031690057\n",
      "Iteration 1690, cv error=0.155553081398, train error=0.0814296960359\n",
      "Iteration 1691, cv error=0.155456749702, train error=0.081356341951\n",
      "Iteration 1692, cv error=0.155360562347, train error=0.0812831064808\n",
      "Iteration 1693, cv error=0.155264519015, train error=0.0812099893557\n",
      "Iteration 1694, cv error=0.155168619388, train error=0.0811369903072\n",
      "Iteration 1695, cv error=0.15507286315, train error=0.0810641090673\n",
      "Iteration 1696, cv error=0.154977249985, train error=0.0809913453689\n",
      "Iteration 1697, cv error=0.154881779579, train error=0.0809186989456\n",
      "Iteration 1698, cv error=0.154786451619, train error=0.0808461695317\n",
      "Iteration 1699, cv error=0.154691265791, train error=0.0807737568624\n",
      "Iteration 1700, cv error=0.154596221784, train error=0.0807014606736\n",
      "Iteration 1701, cv error=0.154501319286, train error=0.080629280702\n",
      "Iteration 1702, cv error=0.154406557987, train error=0.080557216685\n",
      "Iteration 1703, cv error=0.154311937578, train error=0.0804852683607\n",
      "Iteration 1704, cv error=0.15421745775, train error=0.0804134354681\n",
      "Iteration 1705, cv error=0.154123118195, train error=0.0803417177467\n",
      "Iteration 1706, cv error=0.154028918608, train error=0.0802701149371\n",
      "Iteration 1707, cv error=0.153934858681, train error=0.0801986267803\n",
      "Iteration 1708, cv error=0.15384093811, train error=0.0801272530182\n",
      "Iteration 1709, cv error=0.15374715659, train error=0.0800559933934\n",
      "Iteration 1710, cv error=0.153653513818, train error=0.0799848476493\n",
      "Iteration 1711, cv error=0.153560009492, train error=0.0799138155299\n",
      "Iteration 1712, cv error=0.153466643309, train error=0.07984289678\n",
      "Iteration 1713, cv error=0.153373414969, train error=0.0797720911452\n",
      "Iteration 1714, cv error=0.153280324171, train error=0.0797013983718\n",
      "Iteration 1715, cv error=0.153187370617, train error=0.0796308182065\n",
      "Iteration 1716, cv error=0.153094554007, train error=0.0795603503973\n",
      "Iteration 1717, cv error=0.153001874045, train error=0.0794899946924\n",
      "Iteration 1718, cv error=0.152909330433, train error=0.079419750841\n",
      "Iteration 1719, cv error=0.152816922875, train error=0.0793496185929\n",
      "Iteration 1720, cv error=0.152724651076, train error=0.0792795976987\n",
      "Iteration 1721, cv error=0.152632514743, train error=0.0792096879096\n",
      "Iteration 1722, cv error=0.15254051358, train error=0.0791398889774\n",
      "Iteration 1723, cv error=0.152448647296, train error=0.079070200655\n",
      "Iteration 1724, cv error=0.152356915598, train error=0.0790006226956\n",
      "Iteration 1725, cv error=0.152265318196, train error=0.0789311548532\n",
      "Iteration 1726, cv error=0.152173854799, train error=0.0788617968827\n",
      "Iteration 1727, cv error=0.152082525117, train error=0.0787925485394\n",
      "Iteration 1728, cv error=0.151991328861, train error=0.0787234095794\n",
      "Iteration 1729, cv error=0.151900265745, train error=0.0786543797596\n",
      "Iteration 1730, cv error=0.15180933548, train error=0.0785854588374\n",
      "Iteration 1731, cv error=0.15171853778, train error=0.078516646571\n",
      "Iteration 1732, cv error=0.151627872359, train error=0.0784479427193\n",
      "Iteration 1733, cv error=0.151537338933, train error=0.0783793470418\n",
      "Iteration 1734, cv error=0.151446937218, train error=0.0783108592987\n",
      "Iteration 1735, cv error=0.15135666693, train error=0.0782424792508\n",
      "Iteration 1736, cv error=0.151266527786, train error=0.0781742066598\n",
      "Iteration 1737, cv error=0.151176519506, train error=0.0781060412879\n",
      "Iteration 1738, cv error=0.151086641808, train error=0.0780379828979\n",
      "Iteration 1739, cv error=0.150996894411, train error=0.0779700312534\n",
      "Iteration 1740, cv error=0.150907277037, train error=0.0779021861186\n",
      "Iteration 1741, cv error=0.150817789407, train error=0.0778344472584\n",
      "Iteration 1742, cv error=0.150728431242, train error=0.0777668144383\n",
      "Iteration 1743, cv error=0.150639202266, train error=0.0776992874245\n",
      "Iteration 1744, cv error=0.150550102203, train error=0.0776318659838\n",
      "Iteration 1745, cv error=0.150461130775, train error=0.0775645498838\n",
      "Iteration 1746, cv error=0.15037228771, train error=0.0774973388926\n",
      "Iteration 1747, cv error=0.150283572731, train error=0.0774302327789\n",
      "Iteration 1748, cv error=0.150194985567, train error=0.0773632313122\n",
      "Iteration 1749, cv error=0.150106525945, train error=0.0772963342627\n",
      "Iteration 1750, cv error=0.150018193591, train error=0.0772295414009\n",
      "Iteration 1751, cv error=0.149929988236, train error=0.0771628524982\n",
      "Iteration 1752, cv error=0.149841909609, train error=0.0770962673268\n",
      "Iteration 1753, cv error=0.149753957439, train error=0.0770297856591\n",
      "Iteration 1754, cv error=0.149666131459, train error=0.0769634072684\n",
      "Iteration 1755, cv error=0.149578431399, train error=0.0768971319286\n",
      "Iteration 1756, cv error=0.149490856993, train error=0.0768309594143\n",
      "Iteration 1757, cv error=0.149403407973, train error=0.0767648895006\n",
      "Iteration 1758, cv error=0.149316084073, train error=0.0766989219633\n",
      "Iteration 1759, cv error=0.149228885029, train error=0.0766330565787\n",
      "Iteration 1760, cv error=0.149141810574, train error=0.0765672931238\n",
      "Iteration 1761, cv error=0.149054860446, train error=0.0765016313763\n",
      "Iteration 1762, cv error=0.148968034381, train error=0.0764360711144\n",
      "Iteration 1763, cv error=0.148881332116, train error=0.076370612117\n",
      "Iteration 1764, cv error=0.14879475339, train error=0.0763052541636\n",
      "Iteration 1765, cv error=0.148708297942, train error=0.0762399970342\n",
      "Iteration 1766, cv error=0.14862196551, train error=0.0761748405095\n",
      "Iteration 1767, cv error=0.148535755837, train error=0.0761097843707\n",
      "Iteration 1768, cv error=0.148449668661, train error=0.0760448283999\n",
      "Iteration 1769, cv error=0.148363703726, train error=0.0759799723795\n",
      "Iteration 1770, cv error=0.148277860774, train error=0.0759152160925\n",
      "Iteration 1771, cv error=0.148192139547, train error=0.0758505593227\n",
      "Iteration 1772, cv error=0.148106539789, train error=0.0757860018544\n",
      "Iteration 1773, cv error=0.148021061245, train error=0.0757215434724\n",
      "Iteration 1774, cv error=0.147935703661, train error=0.0756571839622\n",
      "Iteration 1775, cv error=0.147850466781, train error=0.0755929231099\n",
      "Iteration 1776, cv error=0.147765350352, train error=0.0755287607022\n",
      "Iteration 1777, cv error=0.147680354122, train error=0.0754646965262\n",
      "Iteration 1778, cv error=0.147595477838, train error=0.0754007303698\n",
      "Iteration 1779, cv error=0.14751072125, train error=0.0753368620214\n",
      "Iteration 1780, cv error=0.147426084105, train error=0.07527309127\n",
      "Iteration 1781, cv error=0.147341566154, train error=0.0752094179051\n",
      "Iteration 1782, cv error=0.147257167148, train error=0.0751458417169\n",
      "Iteration 1783, cv error=0.147172886838, train error=0.0750823624961\n",
      "Iteration 1784, cv error=0.147088724976, train error=0.075018980034\n",
      "Iteration 1785, cv error=0.147004681314, train error=0.0749556941224\n",
      "Iteration 1786, cv error=0.146920755605, train error=0.0748925045538\n",
      "Iteration 1787, cv error=0.146836947604, train error=0.0748294111211\n",
      "Iteration 1788, cv error=0.146753257064, train error=0.074766413618\n",
      "Iteration 1789, cv error=0.146669683742, train error=0.0747035118384\n",
      "Iteration 1790, cv error=0.146586227392, train error=0.0746407055772\n",
      "Iteration 1791, cv error=0.146502887772, train error=0.0745779946296\n",
      "Iteration 1792, cv error=0.146419664638, train error=0.0745153787913\n",
      "Iteration 1793, cv error=0.146336557749, train error=0.0744528578587\n",
      "Iteration 1794, cv error=0.146253566863, train error=0.0743904316288\n",
      "Iteration 1795, cv error=0.146170691738, train error=0.0743280998989\n",
      "Iteration 1796, cv error=0.146087932135, train error=0.0742658624671\n",
      "Iteration 1797, cv error=0.146005287814, train error=0.0742037191321\n",
      "Iteration 1798, cv error=0.145922758536, train error=0.0741416696927\n",
      "Iteration 1799, cv error=0.145840344062, train error=0.0740797139488\n",
      "Iteration 1800, cv error=0.145758044155, train error=0.0740178517006\n",
      "Iteration 1801, cv error=0.145675858578, train error=0.0739560827487\n",
      "Iteration 1802, cv error=0.145593787094, train error=0.0738944068944\n",
      "Iteration 1803, cv error=0.145511829467, train error=0.0738328239397\n",
      "Iteration 1804, cv error=0.145429985462, train error=0.0737713336867\n",
      "Iteration 1805, cv error=0.145348254845, train error=0.0737099359385\n",
      "Iteration 1806, cv error=0.145266637382, train error=0.0736486304984\n",
      "Iteration 1807, cv error=0.145185132838, train error=0.0735874171704\n",
      "Iteration 1808, cv error=0.145103740982, train error=0.0735262957589\n",
      "Iteration 1809, cv error=0.145022461581, train error=0.073465266069\n",
      "Iteration 1810, cv error=0.144941294405, train error=0.0734043279063\n",
      "Iteration 1811, cv error=0.144860239221, train error=0.0733434810768\n",
      "Iteration 1812, cv error=0.144779295799, train error=0.073282725387\n",
      "Iteration 1813, cv error=0.144698463911, train error=0.0732220606441\n",
      "Iteration 1814, cv error=0.144617743326, train error=0.0731614866557\n",
      "Iteration 1815, cv error=0.144537133817, train error=0.0731010032299\n",
      "Iteration 1816, cv error=0.144456635155, train error=0.0730406101755\n",
      "Iteration 1817, cv error=0.144376247113, train error=0.0729803073015\n",
      "Iteration 1818, cv error=0.144295969465, train error=0.0729200944177\n",
      "Iteration 1819, cv error=0.144215801984, train error=0.0728599713343\n",
      "Iteration 1820, cv error=0.144135744445, train error=0.0727999378619\n",
      "Iteration 1821, cv error=0.144055796624, train error=0.0727399938118\n",
      "Iteration 1822, cv error=0.143975958295, train error=0.0726801389958\n",
      "Iteration 1823, cv error=0.143896229235, train error=0.072620373226\n",
      "Iteration 1824, cv error=0.143816609222, train error=0.0725606963151\n",
      "Iteration 1825, cv error=0.143737098031, train error=0.0725011080764\n",
      "Iteration 1826, cv error=0.143657695442, train error=0.0724416083237\n",
      "Iteration 1827, cv error=0.143578401234, train error=0.0723821968711\n",
      "Iteration 1828, cv error=0.143499215184, train error=0.0723228735334\n",
      "Iteration 1829, cv error=0.143420137074, train error=0.0722636381258\n",
      "Iteration 1830, cv error=0.143341166683, train error=0.072204490464\n",
      "Iteration 1831, cv error=0.143262303793, train error=0.0721454303642\n",
      "Iteration 1832, cv error=0.143183548185, train error=0.0720864576431\n",
      "Iteration 1833, cv error=0.143104899641, train error=0.072027572118\n",
      "Iteration 1834, cv error=0.143026357943, train error=0.0719687736064\n",
      "Iteration 1835, cv error=0.142947922876, train error=0.0719100619265\n",
      "Iteration 1836, cv error=0.142869594222, train error=0.071851436897\n",
      "Iteration 1837, cv error=0.142791371766, train error=0.0717928983369\n",
      "Iteration 1838, cv error=0.142713255294, train error=0.071734446066\n",
      "Iteration 1839, cv error=0.14263524459, train error=0.0716760799043\n",
      "Iteration 1840, cv error=0.14255733944, train error=0.0716177996722\n",
      "Iteration 1841, cv error=0.142479539632, train error=0.071559605191\n",
      "Iteration 1842, cv error=0.142401844952, train error=0.071501496282\n",
      "Iteration 1843, cv error=0.142324255188, train error=0.0714434727673\n",
      "Iteration 1844, cv error=0.142246770129, train error=0.0713855344694\n",
      "Iteration 1845, cv error=0.142169389562, train error=0.0713276812111\n",
      "Iteration 1846, cv error=0.142092113279, train error=0.0712699128158\n",
      "Iteration 1847, cv error=0.142014941067, train error=0.0712122291075\n",
      "Iteration 1848, cv error=0.141937872719, train error=0.0711546299104\n",
      "Iteration 1849, cv error=0.141860908024, train error=0.0710971150494\n",
      "Iteration 1850, cv error=0.141784046775, train error=0.0710396843497\n",
      "Iteration 1851, cv error=0.141707288764, train error=0.070982337637\n",
      "Iteration 1852, cv error=0.141630633782, train error=0.0709250747374\n",
      "Iteration 1853, cv error=0.141554081624, train error=0.0708678954777\n",
      "Iteration 1854, cv error=0.141477632083, train error=0.070810799685\n",
      "Iteration 1855, cv error=0.141401284954, train error=0.0707537871867\n",
      "Iteration 1856, cv error=0.14132504003, train error=0.0706968578109\n",
      "Iteration 1857, cv error=0.141248897108, train error=0.070640011386\n",
      "Iteration 1858, cv error=0.141172855983, train error=0.070583247741\n",
      "Iteration 1859, cv error=0.141096916452, train error=0.0705265667052\n",
      "Iteration 1860, cv error=0.141021078311, train error=0.0704699681084\n",
      "Iteration 1861, cv error=0.140945341358, train error=0.0704134517809\n",
      "Iteration 1862, cv error=0.140869705391, train error=0.0703570175533\n",
      "Iteration 1863, cv error=0.140794170208, train error=0.0703006652568\n",
      "Iteration 1864, cv error=0.140718735608, train error=0.070244394723\n",
      "Iteration 1865, cv error=0.140643401391, train error=0.070188205784\n",
      "Iteration 1866, cv error=0.140568167357, train error=0.0701320982721\n",
      "Iteration 1867, cv error=0.140493033306, train error=0.0700760720203\n",
      "Iteration 1868, cv error=0.140417999039, train error=0.070020126862\n",
      "Iteration 1869, cv error=0.140343064359, train error=0.0699642626308\n",
      "Iteration 1870, cv error=0.140268229066, train error=0.0699084791611\n",
      "Iteration 1871, cv error=0.140193492964, train error=0.0698527762875\n",
      "Iteration 1872, cv error=0.140118855855, train error=0.069797153845\n",
      "Iteration 1873, cv error=0.140044317544, train error=0.0697416116692\n",
      "Iteration 1874, cv error=0.139969877834, train error=0.069686149596\n",
      "Iteration 1875, cv error=0.13989553653, train error=0.0696307674617\n",
      "Iteration 1876, cv error=0.139821293437, train error=0.0695754651033\n",
      "Iteration 1877, cv error=0.13974714836, train error=0.0695202423578\n",
      "Iteration 1878, cv error=0.139673101107, train error=0.0694650990629\n",
      "Iteration 1879, cv error=0.139599151482, train error=0.0694100350567\n",
      "Iteration 1880, cv error=0.139525299294, train error=0.0693550501777\n",
      "Iteration 1881, cv error=0.13945154435, train error=0.0693001442647\n",
      "Iteration 1882, cv error=0.139377886458, train error=0.0692453171572\n",
      "Iteration 1883, cv error=0.139304325426, train error=0.0691905686948\n",
      "Iteration 1884, cv error=0.139230861064, train error=0.0691358987177\n",
      "Iteration 1885, cv error=0.139157493181, train error=0.0690813070664\n",
      "Iteration 1886, cv error=0.139084221588, train error=0.069026793582\n",
      "Iteration 1887, cv error=0.139011046094, train error=0.0689723581059\n",
      "Iteration 1888, cv error=0.138937966511, train error=0.0689180004798\n",
      "Iteration 1889, cv error=0.138864982651, train error=0.068863720546\n",
      "Iteration 1890, cv error=0.138792094324, train error=0.0688095181471\n",
      "Iteration 1891, cv error=0.138719301344, train error=0.0687553931261\n",
      "Iteration 1892, cv error=0.138646603524, train error=0.0687013453265\n",
      "Iteration 1893, cv error=0.138574000676, train error=0.0686473745921\n",
      "Iteration 1894, cv error=0.138501492616, train error=0.0685934807671\n",
      "Iteration 1895, cv error=0.138429079156, train error=0.0685396636963\n",
      "Iteration 1896, cv error=0.138356760113, train error=0.0684859232246\n",
      "Iteration 1897, cv error=0.138284535301, train error=0.0684322591975\n",
      "Iteration 1898, cv error=0.138212404536, train error=0.0683786714608\n",
      "Iteration 1899, cv error=0.138140367634, train error=0.0683251598608\n",
      "Iteration 1900, cv error=0.138068424412, train error=0.0682717242442\n",
      "Iteration 1901, cv error=0.137996574687, train error=0.0682183644578\n",
      "Iteration 1902, cv error=0.137924818277, train error=0.0681650803493\n",
      "Iteration 1903, cv error=0.137853154999, train error=0.0681118717664\n",
      "Iteration 1904, cv error=0.137781584673, train error=0.0680587385572\n",
      "Iteration 1905, cv error=0.137710107117, train error=0.0680056805705\n",
      "Iteration 1906, cv error=0.137638722151, train error=0.0679526976552\n",
      "Iteration 1907, cv error=0.137567429595, train error=0.0678997896606\n",
      "Iteration 1908, cv error=0.137496229269, train error=0.0678469564365\n",
      "Iteration 1909, cv error=0.137425120994, train error=0.0677941978331\n",
      "Iteration 1910, cv error=0.137354104591, train error=0.0677415137009\n",
      "Iteration 1911, cv error=0.137283179881, train error=0.0676889038908\n",
      "Iteration 1912, cv error=0.137212346688, train error=0.0676363682541\n",
      "Iteration 1913, cv error=0.137141604834, train error=0.0675839066425\n",
      "Iteration 1914, cv error=0.137070954141, train error=0.067531518908\n",
      "Iteration 1915, cv error=0.137000394434, train error=0.067479204903\n",
      "Iteration 1916, cv error=0.136929925536, train error=0.0674269644804\n",
      "Iteration 1917, cv error=0.136859547271, train error=0.0673747974933\n",
      "Iteration 1918, cv error=0.136789259465, train error=0.0673227037954\n",
      "Iteration 1919, cv error=0.136719061943, train error=0.0672706832404\n",
      "Iteration 1920, cv error=0.136648954531, train error=0.0672187356827\n",
      "Iteration 1921, cv error=0.136578937054, train error=0.0671668609771\n",
      "Iteration 1922, cv error=0.13650900934, train error=0.0671150589784\n",
      "Iteration 1923, cv error=0.136439171214, train error=0.0670633295422\n",
      "Iteration 1924, cv error=0.136369422506, train error=0.0670116725243\n",
      "Iteration 1925, cv error=0.136299763042, train error=0.0669600877806\n",
      "Iteration 1926, cv error=0.136230192652, train error=0.0669085751679\n",
      "Iteration 1927, cv error=0.136160711163, train error=0.0668571345429\n",
      "Iteration 1928, cv error=0.136091318405, train error=0.0668057657628\n",
      "Iteration 1929, cv error=0.136022014208, train error=0.0667544686854\n",
      "Iteration 1930, cv error=0.135952798402, train error=0.0667032431684\n",
      "Iteration 1931, cv error=0.135883670817, train error=0.0666520890704\n",
      "Iteration 1932, cv error=0.135814631284, train error=0.0666010062498\n",
      "Iteration 1933, cv error=0.135745679634, train error=0.0665499945658\n",
      "Iteration 1934, cv error=0.135676815699, train error=0.0664990538778\n",
      "Iteration 1935, cv error=0.135608039312, train error=0.0664481840454\n",
      "Iteration 1936, cv error=0.135539350304, train error=0.0663973849289\n",
      "Iteration 1937, cv error=0.13547074851, train error=0.0663466563886\n",
      "Iteration 1938, cv error=0.135402233761, train error=0.0662959982854\n",
      "Iteration 1939, cv error=0.135333805893, train error=0.0662454104803\n",
      "Iteration 1940, cv error=0.135265464739, train error=0.066194892835\n",
      "Iteration 1941, cv error=0.135197210134, train error=0.0661444452113\n",
      "Iteration 1942, cv error=0.135129041913, train error=0.0660940674714\n",
      "Iteration 1943, cv error=0.135060959912, train error=0.0660437594777\n",
      "Iteration 1944, cv error=0.134992963966, train error=0.0659935210933\n",
      "Iteration 1945, cv error=0.134925053912, train error=0.0659433521814\n",
      "Iteration 1946, cv error=0.134857229586, train error=0.0658932526055\n",
      "Iteration 1947, cv error=0.134789490825, train error=0.0658432222296\n",
      "Iteration 1948, cv error=0.134721837468, train error=0.0657932609179\n",
      "Iteration 1949, cv error=0.134654269352, train error=0.0657433685351\n",
      "Iteration 1950, cv error=0.134586786315, train error=0.0656935449461\n",
      "Iteration 1951, cv error=0.134519388195, train error=0.0656437900162\n",
      "Iteration 1952, cv error=0.134452074833, train error=0.0655941036109\n",
      "Iteration 1953, cv error=0.134384846068, train error=0.0655444855964\n",
      "Iteration 1954, cv error=0.134317701739, train error=0.0654949358388\n",
      "Iteration 1955, cv error=0.134250641686, train error=0.0654454542048\n",
      "Iteration 1956, cv error=0.134183665751, train error=0.0653960405614\n",
      "Iteration 1957, cv error=0.134116773775, train error=0.0653466947758\n",
      "Iteration 1958, cv error=0.134049965599, train error=0.0652974167158\n",
      "Iteration 1959, cv error=0.133983241065, train error=0.0652482062491\n",
      "Iteration 1960, cv error=0.133916600014, train error=0.0651990632442\n",
      "Iteration 1961, cv error=0.133850042291, train error=0.0651499875697\n",
      "Iteration 1962, cv error=0.133783567738, train error=0.0651009790944\n",
      "Iteration 1963, cv error=0.133717176197, train error=0.0650520376877\n",
      "Iteration 1964, cv error=0.133650867514, train error=0.0650031632191\n",
      "Iteration 1965, cv error=0.133584641533, train error=0.0649543555587\n",
      "Iteration 1966, cv error=0.133518498097, train error=0.0649056145765\n",
      "Iteration 1967, cv error=0.133452437052, train error=0.0648569401432\n",
      "Iteration 1968, cv error=0.133386458243, train error=0.0648083321297\n",
      "Iteration 1969, cv error=0.133320561516, train error=0.0647597904072\n",
      "Iteration 1970, cv error=0.133254746717, train error=0.0647113148472\n",
      "Iteration 1971, cv error=0.133189013692, train error=0.0646629053215\n",
      "Iteration 1972, cv error=0.133123362289, train error=0.0646145617023\n",
      "Iteration 1973, cv error=0.133057792354, train error=0.0645662838622\n",
      "Iteration 1974, cv error=0.132992303735, train error=0.0645180716738\n",
      "Iteration 1975, cv error=0.132926896281, train error=0.0644699250103\n",
      "Iteration 1976, cv error=0.132861569839, train error=0.0644218437452\n",
      "Iteration 1977, cv error=0.132796324258, train error=0.0643738277521\n",
      "Iteration 1978, cv error=0.132731159387, train error=0.0643258769052\n",
      "Iteration 1979, cv error=0.132666075076, train error=0.0642779910787\n",
      "Iteration 1980, cv error=0.132601071175, train error=0.0642301701474\n",
      "Iteration 1981, cv error=0.132536147533, train error=0.0641824139862\n",
      "Iteration 1982, cv error=0.132471304002, train error=0.0641347224705\n",
      "Iteration 1983, cv error=0.132406540432, train error=0.0640870954757\n",
      "Iteration 1984, cv error=0.132341856674, train error=0.0640395328779\n",
      "Iteration 1985, cv error=0.132277252581, train error=0.0639920345533\n",
      "Iteration 1986, cv error=0.132212728003, train error=0.0639446003782\n",
      "Iteration 1987, cv error=0.132148282794, train error=0.0638972302297\n",
      "Iteration 1988, cv error=0.132083916806, train error=0.0638499239847\n",
      "Iteration 1989, cv error=0.132019629893, train error=0.0638026815207\n",
      "Iteration 1990, cv error=0.131955421907, train error=0.0637555027155\n",
      "Iteration 1991, cv error=0.131891292703, train error=0.063708387447\n",
      "Iteration 1992, cv error=0.131827242134, train error=0.0636613355936\n",
      "Iteration 1993, cv error=0.131763270056, train error=0.0636143470339\n",
      "Iteration 1994, cv error=0.131699376322, train error=0.0635674216468\n",
      "Iteration 1995, cv error=0.131635560789, train error=0.0635205593116\n",
      "Iteration 1996, cv error=0.131571823312, train error=0.0634737599077\n",
      "Iteration 1997, cv error=0.131508163746, train error=0.0634270233149\n",
      "Iteration 1998, cv error=0.131444581948, train error=0.0633803494135\n",
      "Iteration 1999, cv error=0.131381077775, train error=0.0633337380836\n"
     ]
    }
   ],
   "source": [
    "errors_train, errors_val = mlp.fit(train_data, train_target, val_data, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57871442361\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10813ded0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print errors_train[0]\n",
    "pl.plot(errors_train, label=\"train\")\n",
    "pl.plot(errors_val, label=\"valid\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 207/207\n",
      "Validation accuracy 53/53\n"
     ]
    }
   ],
   "source": [
    "val_prediction = mlp.predict(val_data)\n",
    "val_ans = np.argmax(val_prediction, axis=1)\n",
    "\n",
    "train_prediction = mlp.predict(train_data)\n",
    "train_ans = np.argmax(train_prediction, axis=1)\n",
    "\n",
    "print \"Train accuracy %d/%d\" % ((train_ans == train_classes).sum(), train_classes.size) \n",
    "print \"Validation accuracy %d/%d\" % ((val_ans == val_classes).sum(), val_ans.size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-983a72f4d9af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mres_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mres_train_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mls1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-fd45bae69b11>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, add_bias)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m#print tmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/feldsherov/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(a, order)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;31m# Basic operations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eps = 1e-4\n",
    "nGradW = [None]*len(mlp.w)\n",
    "for t in range(len(mlp.w)):\n",
    "    nGradW[t] = np.zeros(mlp.w[t].shape[0] * mlp.w[t].shape[1]).reshape(mlp.w[t].shape[0], mlp.w[t].shape[1])\n",
    "    for i in range(mlp.w[t].shape[0]):\n",
    "        for j in range(mlp.w[t].shape[1]):    \n",
    "            res_train = mlp.predict(train_data)\n",
    "            mlp.w[t][i][j] += eps\n",
    "            res_train_new = mlp.predict(train_data)\n",
    "            mlp.w[t][i][j] -= eps            \n",
    "            ls1 = mlp.loss(res_train, train_target)\n",
    "            ls2 = mlp.loss(res_train_new, train_target)\n",
    "            nGradW[t][i][j] = ((ls1 - ls2) / eps).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
